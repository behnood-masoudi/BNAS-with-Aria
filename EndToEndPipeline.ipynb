{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdf8f00e-e3bb-423f-b247-d9ec72da7a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "video_name = \"Pierre_INM_3\"  # default value for development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5600c625-201d-43b6-b268-3609dab07e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import gzip\n",
    "from matplotlib import cm\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import yolox\n",
    "from yolox.tracker.byte_tracker import BYTETracker\n",
    "from yolox.tracker.byte_tracker import STrack\n",
    "import torch\n",
    "from scipy.spatial.transform import Rotation as R_scipy\n",
    "from pykalman import KalmanFilter\n",
    "import open3d as o3d\n",
    "\n",
    "\n",
    "# Project Aria Imports\n",
    "import projectaria_tools.core.mps as mps\n",
    "from projectaria_tools.core import data_provider\n",
    "from projectaria_tools.core.mps.utils import get_nearest_pose\n",
    "from projectaria_tools.core.stream_id import StreamId\n",
    "from projectaria_tools.core.calibration import (distort_by_calibration, get_linear_camera_calibration)\n",
    "from projectaria_tools.core.sensor_data import TimeDomain, TimeQueryOptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "357b77ee-2e7f-4918-a381-b9d3f4a59149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded #closed loop trajectory poses records: 11301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;2;000;000;255m[ProgressLogger][INFO]: 2025-07-23 18:51:20: Opening /Users/behnood/Downloads/S - Master Thesis - EPFL/Aria Recordings/Pierre/Pierre_INM_3.vrs...\u001b[0m\n",
      "\u001b[0m\u001b[38;2;255;165;000m[VRSIndexRecord][WARNING]: 1 record(s) not sorted properly. Sorting index.\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;128;000m[MultiRecordFileReader][DEBUG]: Opened file '/Users/behnood/Downloads/S - Master Thesis - EPFL/Aria Recordings/Pierre/Pierre_INM_3.vrs' and assigned to reader #0\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;000;255m[VrsDataProvider][INFO]: streamId 211-1/camera-et activated\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;000;255m[VrsDataProvider][INFO]: streamId 214-1/camera-rgb activated\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;000;255m[VrsDataProvider][INFO]: streamId 231-1/mic activated\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;000;255m[VrsDataProvider][INFO]: streamId 247-1/baro0 activated\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;000;255m[VrsDataProvider][INFO]: streamId 281-1/gps activated\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;000;255m[VrsDataProvider][INFO]: streamId 282-1/wps activated\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;000;255m[VrsDataProvider][INFO]: streamId 283-1/bluetooth activated\u001b[0m\n",
      "\u001b[0m\u001b[38;2;255;165;000m[VrsDataProvider][WARNING]: Unsupported TimeSync mode: APP, ignoring.\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;000;255m[VrsDataProvider][INFO]: Fail to activate streamId 286-1\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;000;255m[VrsDataProvider][INFO]: streamId 1201-1/camera-slam-left activated\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;000;255m[VrsDataProvider][INFO]: streamId 1201-2/camera-slam-right activated\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;000;255m[VrsDataProvider][INFO]: streamId 1202-1/imu-right activated\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;000;255m[VrsDataProvider][INFO]: streamId 1202-2/imu-left activated\u001b[0m\n",
      "\u001b[0m\u001b[38;2;000;000;255m[VrsDataProvider][INFO]: streamId 1203-1/mag0 activated\u001b[0m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# # Input: Video (VRS file) + Slam Trajectories (With Aria SDK)\n",
    "\n",
    "# closed_loop_path = \"/Users/behnood/Downloads/S - Master Thesis - EPFL/Aria Recordings/Pierre/mps_Nas_InCM_65_vrs/slam/closed_loop_trajectory.csv\"\n",
    "# closed_loop_trajectory = mps.read_closed_loop_trajectory(closed_loop_path)\n",
    "\n",
    "# vrs_file = \"/Users/behnood/Downloads/S - Master Thesis - EPFL/Aria Recordings/Pierre/Nas_InCM_65.vrs\"\n",
    "# vrs_data_provider = data_provider.create_vrs_data_provider(vrs_file)\n",
    "\n",
    "# semidense_points_path = \"/Users/behnood/Downloads/S - Master Thesis - EPFL/Aria Recordings/Pierre/mps_Nas_InCM_65_vrs/slam/semidense_points.csv.gz\"\n",
    "\n",
    "# video_name = \"Pierre_INM_1\"\n",
    "base_dir = \"/Users/behnood/Downloads/S - Master Thesis - EPFL/Aria Recordings/Pierre\"\n",
    "\n",
    "# Build paths dynamically\n",
    "vrs_file = os.path.join(base_dir, f\"{video_name}.vrs\")\n",
    "closed_loop_path = os.path.join(base_dir, f\"mps_{video_name}_vrs/slam/closed_loop_trajectory.csv\")\n",
    "semidense_points_path = os.path.join(base_dir, f\"mps_{video_name}_vrs/slam/semidense_points.csv.gz\")\n",
    "\n",
    "# Load data\n",
    "closed_loop_trajectory = mps.read_closed_loop_trajectory(closed_loop_path)\n",
    "vrs_data_provider = data_provider.create_vrs_data_provider(vrs_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c9429e3-77d6-40c1-89b6-e2e0ca42b028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load YOLO Model (use \"yolov8n.pt\" for speed, or \"yolov8m.pt\" for better accuracy)\n",
    "model = YOLO(\"yolov8m.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f78b4a24-35ea-48d1-b21f-f23f4d7aba20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CameraCalibration(label: camera-rgb, model name: Fisheye624, principal point: [710.741, 706.47], focal length: [611.091, 611.091], projection params: [611.091, 710.741, 706.47, 0.389076, -0.376021, -0.205402, 1.71844, -2.11538, 0.760929, -0.000219489, 0.000306255, 0.000164677, -0.000154579, -0.000721263, -0.000195109], image size (w,h): [1408, 1408], T_Device_Camera:(translation:[-0.00457615, -0.0118596, -0.0047664], quaternion(x,y,z,w):[0.329176, 0.0368128, 0.0306198, 0.943054]), serialNumber:0450577b730407504401100000000000, TimeOffsetSec_Device_Camera:0)\n"
     ]
    }
   ],
   "source": [
    "# Calculate RGB Camera Instrinsics\n",
    "\n",
    "rgb_stream_id = StreamId(\"214-1\")\n",
    "rgb_stream_label = vrs_data_provider.get_label_from_stream_id(rgb_stream_id)\n",
    "device_calibration = vrs_data_provider.get_device_calibration()\n",
    "rgb_camera_calibration = device_calibration.get_camera_calib(rgb_stream_label)\n",
    "print(rgb_camera_calibration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ccbadbe-2ff0-4492-a904-205c401fe330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t:  [-0.004576149851854918, -0.01185964032054523, -0.004766398952129968] \n",
      "R:  [[[    0.78058     0.61861    0.089592]\n",
      "  [    0.62312    -0.78141   -0.033516]\n",
      "  [   0.049274    0.081988    -0.99541]]]\n"
     ]
    }
   ],
   "source": [
    "# Calculate RGB Camera Extrinsics\n",
    "\n",
    "T_device_camera = rgb_camera_calibration.get_transform_device_camera()\n",
    "principal_point = rgb_camera_calibration.get_principal_point()\n",
    "projection_params = rgb_camera_calibration.get_projection_params()\n",
    "focal_length = [projection_params[0], projection_params[0]]\n",
    "\n",
    "T_device_camera.translation()  \n",
    "translation = T_device_camera.translation()      \n",
    "tx = translation[0][0]  \n",
    "ty = translation[0][1]  \n",
    "tz = translation[0][2]\n",
    "t = [tx, ty, tz]   \n",
    "\n",
    "rotation = T_device_camera.rotation()\n",
    "quaternion = rotation.to_quat() \n",
    "R = R_scipy.from_quat(quaternion).as_matrix()\n",
    "\n",
    "print(\"t: \", t, \"\\nR: \", R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d8687f8-56e5-4677-b0de-a90b9d7dacba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert middle of bounding box to xyz in real world\n",
    "\n",
    "def compute_3d_world_point(bbox, depth_map, principal_point, focal_length, R, t):\n",
    "    x1, y1, x2, y2 = bbox\n",
    "    u = int((x1 + x2) / 2)  \n",
    "    v = int((y1 + y2) / 2)  \n",
    "\n",
    "    return compute_3d_world_point_from_pixel(u, v, depth_map, principal_point, focal_length, R, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5ea7fdd-02f9-4729-8c7b-564125ae0e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert uv in picture, to xyz in real world\n",
    "\n",
    "# First we use camera intrinsics to convert to xyz in camera world, \n",
    "# then we use R and t to convert to xyz in real world\n",
    "\n",
    "def compute_3d_world_point_from_pixel(u, v, depth_map, principal_point, focal_length, R, t):\n",
    "    d = depth_map[v, u]  \n",
    "    \n",
    "    fx, fy = focal_length  \n",
    "    cx, cy = principal_point  \n",
    "\n",
    "    # 3D point in camera coordinates\n",
    "    x = (u - cx) / fx * d  # X coordinate in camera space\n",
    "    y = (v - cy) / fy * d  # Y coordinate in camera space\n",
    "    z = d  # Z coordinate is the depth\n",
    "\n",
    "    # Camera coordinate (x, y, z)\n",
    "    point_cam = np.array([[x], [y], [z]])\n",
    "\n",
    "    # Convert rotation matrix and translation vector to numpy arrays\n",
    "    R = np.array(R)\n",
    "    R = np.squeeze(R)\n",
    "    t = np.array(t).reshape(3, 1)\n",
    "\n",
    "    # Transform to world coordinates\n",
    "    point_world = R @ point_cam + t  # Apply rotation and translation\n",
    "\n",
    "    # Return the 3D point in world coordinates\n",
    "    xw, yw, zw = point_world.flatten() # 1D array [X, Y, Z]\n",
    "    return [yw, xw, -zw]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e78695d9-ce8a-4609-b5ed-4ba114160bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert xyz in real world to uvd in picture (d is for depth)\n",
    "\n",
    "def project_3d_to_pixel_with_depth(world_point, principal_point, focal_length, R, t):\n",
    "    # Unpack world point assuming it's in [y, x, -z] format\n",
    "    y, x, minus_z = world_point\n",
    "    z = -minus_z  # Restore original Z\n",
    "\n",
    "    # Reconstruct world point in original [x, y, z] format\n",
    "    point_world = np.array([[x], [y], [z]])\n",
    "\n",
    "    # Convert R and t to appropriate numpy arrays\n",
    "    R = np.squeeze(np.array(R))\n",
    "    t = np.array(t).reshape(3, 1)\n",
    "\n",
    "    # Invert extrinsic transformation: X_cam = R.T @ (X_world - t)\n",
    "    point_cam = R.T @ (point_world - t)\n",
    "\n",
    "    # Extract camera coordinates\n",
    "    x_cam, y_cam, z_cam = point_cam.flatten()\n",
    "\n",
    "    # Intrinsics\n",
    "    fx, fy = focal_length\n",
    "    cx, cy = principal_point\n",
    "\n",
    "    # Project to pixel coordinates\n",
    "    u = (x_cam * fx) / z_cam + cx\n",
    "    v = (y_cam * fy) / z_cam + cy\n",
    "\n",
    "    u = int(round(u))\n",
    "    v = int(round(v))\n",
    "    \n",
    "    return u, v, z_cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3ae77f1-06fa-4152-bc2f-091771931407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded semidense point cloud: (103695, 3)\n",
      "High Q semidense point cloud: (41583, 3)\n"
     ]
    }
   ],
   "source": [
    "# Unzip and Visualize Semidense Point Cloud from Aria SDK\n",
    "\n",
    "# Unzip (Load and display the first few rows)\n",
    "\n",
    "with gzip.open(semidense_points_path, \"rt\") as f:\n",
    "    df = pd.read_csv(f)\n",
    "\n",
    "semidense_points = df[['px_world', 'py_world', 'pz_world']].to_numpy()\n",
    "print(\"Loaded semidense point cloud:\", semidense_points.shape)\n",
    "dist_std = df['dist_std'].to_numpy()\n",
    "semidense_points = semidense_points[dist_std <= 0.01]\n",
    "print(\"High Q semidense point cloud:\", semidense_points.shape)\n",
    "\n",
    "# Visualize\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(semidense_points)\n",
    "\n",
    "# o3d.visualization.draw_geometries([pcd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6fa443a4-5a7e-41ec-ace9-c90f1ca1d7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for FaceBlur\n",
    "\n",
    "# Skip the warning logs (Not working)\n",
    "os.environ['GLOG_minloglevel'] = '2'  # Suppress INFO and WARNING logs\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # In case TensorFlow logging appears\n",
    "\n",
    "import absl.logging\n",
    "absl.logging.set_verbosity('error')  # Only show error logs, hide info/warnings\n",
    "\n",
    "import mediapipe as mp\n",
    "\n",
    "mp_face_detection = mp.solutions.face_detection\n",
    "\n",
    "\n",
    "def enhance_contrast(image):\n",
    "    lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "    l, a, b = cv2.split(lab)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    cl = clahe.apply(l)\n",
    "    limg = cv2.merge((cl,a,b))\n",
    "    enhanced = cv2.cvtColor(limg, cv2.COLOR_LAB2BGR)\n",
    "    return enhanced\n",
    "    \n",
    "\n",
    "def blur_faces_in_box_mediapipe(frame, box):\n",
    "    \"\"\"\n",
    "    Blurs faces detected within a given person bounding box in a video frame.\n",
    "\n",
    "    Parameters:\n",
    "        frame (np.ndarray): The full video frame (BGR).\n",
    "        box (list): [x1, y1, x2, y2] bounding box coordinates for a person.\n",
    "    \"\"\"\n",
    "\n",
    "    x1, y1, x2, y2 = box\n",
    "    h, w = frame.shape[:2]\n",
    "\n",
    "    # Add margin if needed\n",
    "    margin = 0\n",
    "    x1m = max(0, x1 - margin)\n",
    "    y1m = max(0, y1 - margin)\n",
    "    x2m = min(w, x2 + margin)\n",
    "    y2m = min(h, y2 + margin)\n",
    "\n",
    "    person_roi = frame[y1m:y2m, x1m:x2m]\n",
    "\n",
    "    if person_roi.size == 0:\n",
    "        print(\"empty ROI\")\n",
    "        return  # Empty ROI\n",
    "\n",
    "    enhanced_roi = enhance_contrast(person_roi)\n",
    "\n",
    "    # cv2.imshow(\"enhanced\", enhanced_roi)\n",
    "\n",
    "    # Mediapipe works with RGB images\n",
    "    rgb_roi = cv2.cvtColor(enhanced_roi, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    with mp_face_detection.FaceDetection(model_selection=0, min_detection_confidence=0.2) as face_detection:\n",
    "        results = face_detection.process(rgb_roi)\n",
    "        print(\"Results:\", results)\n",
    "\n",
    "        if not results.detections:\n",
    "            print(\"no faces\")\n",
    "            return  # No faces detected\n",
    "\n",
    "        for detection in results.detections:\n",
    "            # Bounding box relative to the ROI\n",
    "            bboxC = detection.location_data.relative_bounding_box\n",
    "            x_rel = int(bboxC.xmin * person_roi.shape[1])\n",
    "            y_rel = int(bboxC.ymin * person_roi.shape[0])\n",
    "            w_rel = int(bboxC.width * person_roi.shape[1])\n",
    "            h_rel = int(bboxC.height * person_roi.shape[0])\n",
    "\n",
    "            # Coordinates relative to the full frame\n",
    "            fx1 = x1m + x_rel\n",
    "            fy1 = y1m + y_rel\n",
    "            fx2 = fx1 + w_rel\n",
    "            fy2 = fy1 + h_rel\n",
    "\n",
    "            # Clip face coordinates to frame boundaries\n",
    "            fx1 = max(0, fx1)\n",
    "            fy1 = max(0, fy1)\n",
    "            fx2 = min(w, fx2)\n",
    "            fy2 = min(h, fy2)\n",
    "\n",
    "            face_region = frame[fy1:fy2, fx1:fx2]\n",
    "            if face_region.size == 0:\n",
    "                continue\n",
    "\n",
    "            blurred_face = cv2.GaussianBlur(face_region, (51, 51), 30)\n",
    "            frame[fy1:fy2, fx1:fx2] = blurred_face\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a27a1fe-5a0b-463e-976f-63c3aac22ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_trajectory_csv(csv_path):\n",
    "    import os\n",
    "    import csv\n",
    "\n",
    "    if not os.path.exists(csv_path):\n",
    "        with open(csv_path, mode='w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([\n",
    "                \"frame_index\",\n",
    "                \"glasses_x\", \"glasses_y\", \"glasses_z\",\n",
    "                \"opponent_x\", \"opponent_y\", \"opponent_z\",\n",
    "                \"box_x1\", \"box_y1\", \"box_x2\", \"box_y2\",\n",
    "                \"u\", \"v\", \"depth\",\n",
    "                \"principal_x\", \"principal_y\",\n",
    "                \"focal_x\", \"focal_y\",\n",
    "                \"RR_00\", \"RR_01\", \"RR_02\",\n",
    "                \"RR_10\", \"RR_11\", \"RR_12\",\n",
    "                \"RR_20\", \"RR_21\", \"RR_22\",\n",
    "                \"tt_x\", \"tt_y\", \"tt_z\",\n",
    "                \"quat_w\", \"quat_x\", \"quat_y\", \"quat_z\",\n",
    "                \"pedestrians_in_frame\"\n",
    "            ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62e6c145-75ab-4953-891d-11b46efdf3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_trajectory_row(\n",
    "    csv_path, frame_index, tt, object_3d_world_point, box,\n",
    "    depth_map, principal_point, focal_length, RR, q_wxyz, pedestrians_in_frame\n",
    "):\n",
    "    import os\n",
    "    import csv\n",
    "    import json\n",
    "\n",
    "    # Make sure CSV exists and header is written\n",
    "    write_header = not os.path.exists(csv_path)\n",
    "\n",
    "    u = (box[0] + box[2]) // 2\n",
    "    v = (box[1] + box[3]) // 2\n",
    "    depth_value = float(depth_map[v, u])\n",
    "\n",
    "    quat_w, quat_x, quat_y, quat_z = q_wxyz\n",
    "\n",
    "    pedestrians_serialized = json.dumps(pedestrians_in_frame)\n",
    "\n",
    "    row = [\n",
    "        frame_index,\n",
    "        *tt,\n",
    "        *object_3d_world_point,\n",
    "        *box,\n",
    "        u, v, depth_value,\n",
    "        *principal_point,\n",
    "        *focal_length,\n",
    "        *RR.flatten(),\n",
    "        *tt,  # duplicated for clarity\n",
    "        quat_w, quat_x, quat_y, quat_z,\n",
    "        pedestrians_serialized\n",
    "    ]\n",
    "\n",
    "    with open(csv_path, mode='a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "\n",
    "        if write_header:\n",
    "            writer.writerow([\n",
    "                \"frame_index\",\n",
    "                \"glasses_x\", \"glasses_y\", \"glasses_z\",\n",
    "                \"opponent_x\", \"opponent_y\", \"opponent_z\",\n",
    "                \"box_x1\", \"box_y1\", \"box_x2\", \"box_y2\",\n",
    "                \"u\", \"v\", \"depth\",\n",
    "                \"principal_x\", \"principal_y\",\n",
    "                \"focal_x\", \"focal_y\",\n",
    "                \"RR_00\", \"RR_01\", \"RR_02\",\n",
    "                \"RR_10\", \"RR_11\", \"RR_12\",\n",
    "                \"RR_20\", \"RR_21\", \"RR_22\",\n",
    "                \"tt_x\", \"tt_y\", \"tt_z\",\n",
    "                \"quat_w\", \"quat_x\", \"quat_y\", \"quat_z\",\n",
    "                \"pedestrians_serialized\"\n",
    "            ])\n",
    "\n",
    "        writer.writerow(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "895b8f8b-6e6e-4adb-977c-a874937e04ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import DPTForDepthEstimation, DPTImageProcessor\n",
    "\n",
    "model_id = \"depth-anything/Depth-Anything-V2-Metric-Indoor-Base-hf\"\n",
    "pipe = pipeline(\"depth-estimation\", model=model_id, device=0 if torch.cuda.is_available() else -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e779662d-867c-4fdf-9f30-4b9ef72d2a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def improve_depth_scale(depth_pred_map, principal_point, focal_length, R, t):\n",
    "    image_width, image_height = depth_pred_map.shape[1], depth_pred_map.shape[0]\n",
    "    \n",
    "    with gzip.open(semidense_points_path, \"rt\") as f:\n",
    "        df = pd.read_csv(f)\n",
    "    \n",
    "    semidense_points_world = df[['px_world', 'py_world', 'pz_world']].to_numpy()\n",
    "    dist_std = df['dist_std'].to_numpy()\n",
    "    \n",
    "    # Filter for high-quality points\n",
    "    semidense_points_world = semidense_points_world[dist_std <= 0.01]\n",
    "    \n",
    "    # === COMPARE DEPTHS ===\n",
    "    depths_pred = []\n",
    "    depths_real = []\n",
    "    min_pred_depth = 1e-3\n",
    "    \n",
    "    for wp in semidense_points_world:\n",
    "        try:\n",
    "            u, v, z_real = project_3d_to_pixel_with_depth(\n",
    "                world_point=wp,\n",
    "                principal_point=principal_point,\n",
    "                focal_length=focal_length,\n",
    "                R=R,\n",
    "                t=t\n",
    "            )\n",
    "    \n",
    "            # Check bounds\n",
    "            if 0 <= v < image_height and 0 <= u < image_width:\n",
    "                z_pred = depth_pred_map[v, u]\n",
    "                if z_pred > min_pred_depth and z_real > 0:\n",
    "                    depths_pred.append(z_pred)\n",
    "                    depths_real.append(z_real)\n",
    "    \n",
    "        except Exception as e:\n",
    "            continue  # Skip invalid projections\n",
    "\n",
    "    # === COMPUTE SCALE FACTOR ===\n",
    "    depths_pred = np.array(depths_pred)\n",
    "    depths_real = np.array(depths_real)\n",
    "    \n",
    "    if len(depths_pred) > 0:\n",
    "        scale_factor = np.median(depths_real / depths_pred)\n",
    "        print(f\"Estimated scale factor: {scale_factor:.3f}\")\n",
    "        print(f\"Valid depth correspondences: {len(depths_pred)}\")\n",
    "    \n",
    "        # Apply scale to entire depth map\n",
    "        depth_pred_scaled = depth_pred_map * scale_factor\n",
    "        depth_pred_scaled = np.clip(depth_pred_scaled, 0.01, np.percentile(depth_pred_scaled, 99))\n",
    "    else:\n",
    "        print(\"No valid projections for scale correction.\")\n",
    "        scale_factor = 1.0\n",
    "        depth_pred_scaled = depth_pred_map\n",
    "\n",
    "    return depth_pred_scaled, scale_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac39580e-a488-47dd-a226-6410ff63a718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "668400359962\n",
      "668500356837\n",
      "668600357462\n",
      "668700356300\n",
      "668800359800\n",
      "668900354125\n",
      "669000357462\n",
      "669100358712\n",
      "669200363050\n",
      "669300356250\n",
      "▶️ Metric depth range: 1.679136 → 19.979721\n",
      "\n",
      "0: 640x640 4 persons, 1 remote, 168.8ms\n",
      "Speed: 4.9ms preprocess, 168.8ms inference, 4.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Estimated scale factor: 0.325\n",
      "Valid depth correspondences: 3900\n",
      "Scale:  0.32488736178613153\n",
      "0 !!! 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1753289493.516232 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "W0000 00:00:1753289493.525687 5077455 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n",
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 3900\n",
      "Scale:  0.9999999953763202\n",
      "0 !!! 2\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289494.008016 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289494.009535 5077476 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 3900\n",
      "Scale:  0.9999999953763202\n",
      "0 !!! 3\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289494.483152 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289494.484167 5077485 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 3900\n",
      "Scale:  0.9999999953763202\n",
      "0 !!! 4\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n",
      "669400362175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289494.950936 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289494.952231 5077497 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Metric depth range: 1.6667957 → 19.983677\n",
      "\n",
      "0: 640x640 4 persons, 1 remote, 173.3ms\n",
      "Speed: 2.3ms preprocess, 173.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Estimated scale factor: 0.324\n",
      "Valid depth correspondences: 3915\n",
      "Scale:  0.3241559470718229\n",
      "1 !!! 5\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289497.192740 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289497.193864 5077554 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 3915\n",
      "Scale:  0.9999999883435754\n",
      "1 !!! 6\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289497.662195 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289497.663206 5077567 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 3915\n",
      "Scale:  0.9999999883435754\n",
      "1 !!! 7\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289498.122111 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289498.123187 5077579 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 3915\n",
      "Scale:  0.9999999883435754\n",
      "1 !!! 8\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n",
      "669500364175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289498.586606 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289498.587736 5077588 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Metric depth range: 1.6475315 → 19.980331\n",
      "\n",
      "0: 640x640 4 persons, 1 remote, 165.6ms\n",
      "Speed: 2.3ms preprocess, 165.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Estimated scale factor: 0.328\n",
      "Valid depth correspondences: 3951\n",
      "Scale:  0.3276899273608062\n",
      "2 !!! 9\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289500.794030 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289500.795069 5077634 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 3951\n",
      "Scale:  1.0000000842649373\n",
      "2 !!! 10\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289501.252932 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289501.254222 5077651 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 3951\n",
      "Scale:  0.9999999811751421\n",
      "2 !!! 11\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289501.716541 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289501.717738 5077663 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 3951\n",
      "Scale:  0.9999999811751421\n",
      "2 !!! 12\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n",
      "669600364962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289502.180787 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289502.181934 5077677 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Metric depth range: 1.5844715 → 19.971006\n",
      "\n",
      "0: 640x640 5 persons, 1 remote, 223.6ms\n",
      "Speed: 2.9ms preprocess, 223.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Estimated scale factor: 0.331\n",
      "Valid depth correspondences: 4010\n",
      "Scale:  0.33065818617714177\n",
      "3 !!! 13\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289504.583176 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289504.584320 5077733 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 4010\n",
      "Scale:  0.9999999512277938\n",
      "3 !!! 14\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289505.057410 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289505.058602 5077748 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 4010\n",
      "Scale:  1.0000000332429337\n",
      "3 !!! 15\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289505.571984 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289505.573158 5077945 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 4010\n",
      "Scale:  1.0000000332429337\n",
      "3 !!! 16\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289506.054150 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289506.055364 5078004 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 4010\n",
      "Scale:  1.0000000332429337\n",
      "3 !!! 17\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n",
      "669700358000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289506.525956 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289506.527500 5078016 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Metric depth range: 1.4991732 → 19.962423\n",
      "\n",
      "0: 640x640 5 persons, 1 remote, 166.9ms\n",
      "Speed: 2.5ms preprocess, 166.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Estimated scale factor: 0.334\n",
      "Valid depth correspondences: 4073\n",
      "Scale:  0.33389845341508945\n",
      "4 !!! 18\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289509.130019 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289509.131225 5078129 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 4073\n",
      "Scale:  1.0000000169260217\n",
      "4 !!! 19\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289509.597000 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289509.598619 5078142 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 4073\n",
      "Scale:  1.0000000169260217\n",
      "4 !!! 20\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289510.062614 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289510.063891 5078162 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 4073\n",
      "Scale:  1.0000000169260217\n",
      "4 !!! 21\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289510.555218 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289510.556291 5078180 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 4073\n",
      "Scale:  1.0000000169260217\n",
      "4 !!! 22\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n",
      "669800361175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289511.035839 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289511.037376 5078193 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Metric depth range: 1.4198669 → 19.974438\n",
      "\n",
      "0: 640x640 5 persons, 1 remote, 174.1ms\n",
      "Speed: 3.8ms preprocess, 174.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Estimated scale factor: 0.337\n",
      "Valid depth correspondences: 4156\n",
      "Scale:  0.33715154484208054\n",
      "5 !!! 23\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289513.452638 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289513.453703 5078248 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 4156\n",
      "Scale:  0.9999999512559791\n",
      "5 !!! 24\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289513.943786 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289513.944953 5078260 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 4156\n",
      "Scale:  1.0000000148826305\n",
      "5 !!! 25\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289514.405552 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289514.407032 5078273 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 4156\n",
      "Scale:  1.0000000148826305\n",
      "5 !!! 26\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289514.885529 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289514.887289 5078288 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 4156\n",
      "Scale:  1.0000000148826305\n",
      "5 !!! 27\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n",
      "669900361750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289515.377566 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289515.378921 5078300 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Metric depth range: 1.414431 → 19.974827\n",
      "\n",
      "0: 640x640 5 persons, 1 remote, 152.8ms\n",
      "Speed: 3.0ms preprocess, 152.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Estimated scale factor: 0.339\n",
      "Valid depth correspondences: 4230\n",
      "Scale:  0.3389793500873093\n",
      "6 !!! 28\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289517.677720 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289517.678970 5078369 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 4230\n",
      "Scale:  0.9999999842346576\n",
      "6 !!! 29\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289518.143403 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289518.144338 5078388 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 4230\n",
      "Scale:  0.9999999842346576\n",
      "6 !!! 30\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289518.617054 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289518.618197 5078405 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 4230\n",
      "Scale:  0.9999999842346576\n",
      "6 !!! 31\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289519.076490 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289519.077568 5078417 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 4230\n",
      "Scale:  0.9999999842346576\n",
      "6 !!! 32\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n",
      "670000363425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289519.548527 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289519.550505 5078427 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Metric depth range: 1.6654446 → 19.979881\n",
      "\n",
      "0: 640x640 5 persons, 1 remote, 161.6ms\n",
      "Speed: 2.9ms preprocess, 161.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Estimated scale factor: 0.338\n",
      "Valid depth correspondences: 4300\n",
      "Scale:  0.33842491629229066\n",
      "7 !!! 33\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289521.842593 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289521.843829 5078473 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 4300\n",
      "Scale:  0.9999999728650317\n",
      "7 !!! 34\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289522.302183 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289522.303402 5078495 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 4300\n",
      "Scale:  0.9999999728650317\n",
      "7 !!! 35\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289522.777260 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289522.778310 5078514 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 4300\n",
      "Scale:  0.9999999728650317\n",
      "7 !!! 36\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289523.244156 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289523.245284 5078547 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 4300\n",
      "Scale:  0.9999999728650317\n",
      "7 !!! 37\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n",
      "670100357962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289523.714581 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289523.715951 5078569 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Metric depth range: 1.6214774 → 19.978376\n",
      "\n",
      "0: 640x640 5 persons, 1 remote, 182.8ms\n",
      "Speed: 3.6ms preprocess, 182.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Estimated scale factor: 0.340\n",
      "Valid depth correspondences: 4345\n",
      "Scale:  0.33991302737739265\n",
      "8 !!! 38\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289526.121952 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289526.122933 5078605 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 4345\n",
      "Scale:  0.9999999768229139\n",
      "8 !!! 39\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289526.589234 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289526.590358 5078613 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 4345\n",
      "Scale:  0.9999999768229139\n",
      "8 !!! 40\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289527.058638 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289527.059583 5078627 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 4345\n",
      "Scale:  0.9999999768229139\n",
      "8 !!! 41\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289527.528314 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289527.529422 5078634 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 4345\n",
      "Scale:  0.9999999768229139\n",
      "8 !!! 42\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n",
      "670200355037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289528.007727 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289528.009023 5078646 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Metric depth range: 1.8345753 → 19.977379\n",
      "\n",
      "0: 640x640 4 persons, 1 remote, 161.4ms\n",
      "Speed: 2.3ms preprocess, 161.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Estimated scale factor: 0.349\n",
      "Valid depth correspondences: 4393\n",
      "Scale:  0.3485763747977701\n",
      "9 !!! 43\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289530.278500 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289530.280426 5078661 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 4393\n",
      "Scale:  1.0000000302787146\n",
      "9 !!! 44\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289530.760336 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289530.761651 5078754 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 4393\n",
      "Scale:  1.0000000302787146\n",
      "9 !!! 45\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289531.230130 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289531.231272 5078768 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 4393\n",
      "Scale:  1.0000000302787146\n",
      "9 !!! 46\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n",
      "670300361837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289531.701454 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289531.702402 5078776 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Metric depth range: 1.9934993 → 19.97361\n",
      "\n",
      "0: 640x640 3 persons, 1 remote, 189.3ms\n",
      "Speed: 3.2ms preprocess, 189.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Estimated scale factor: 0.362\n",
      "Valid depth correspondences: 4426\n",
      "Scale:  0.36232583976937666\n",
      "10 !!! 47\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289534.138129 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289534.139122 5078822 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 4426\n",
      "Scale:  0.9999999737424881\n",
      "10 !!! 48\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289534.611833 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289534.612828 5078830 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 4426\n",
      "Scale:  0.9999999737424881\n",
      "10 !!! 49\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n",
      "670400358712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289535.088266 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289535.089412 5078846 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Metric depth range: 2.1632552 → 19.980341\n",
      "\n",
      "0: 640x640 3 persons, 1 remote, 170.5ms\n",
      "Speed: 2.9ms preprocess, 170.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Estimated scale factor: 0.365\n",
      "Valid depth correspondences: 4460\n",
      "Scale:  0.3647951732353135\n",
      "11 !!! 50\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289537.433098 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289537.434606 5078890 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 4460\n",
      "Scale:  1.000000004465091\n",
      "11 !!! 51\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289537.916383 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289537.917634 5078899 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 4460\n",
      "Scale:  1.000000004465091\n",
      "11 !!! 52\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n",
      "670500359287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289538.382888 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289538.383985 5078910 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Metric depth range: 2.5396118 → 19.98324\n",
      "\n",
      "0: 640x640 4 persons, 1 remote, 166.3ms\n",
      "Speed: 2.9ms preprocess, 166.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Estimated scale factor: 0.369\n",
      "Valid depth correspondences: 4478\n",
      "Scale:  0.3690079368264423\n",
      "12 !!! 53\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289540.578590 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289540.579581 5078926 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 4478\n",
      "Scale:  0.9999999698580226\n",
      "12 !!! 54\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289541.055863 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289541.056898 5078936 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 4478\n",
      "Scale:  1.0000000309082335\n",
      "12 !!! 55\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289541.520131 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289541.521282 5078945 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 4478\n",
      "Scale:  1.0000000309082335\n",
      "12 !!! 56\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n",
      "670600359925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289542.005299 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289542.006891 5078955 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Metric depth range: 2.609198 → 19.972258\n",
      "\n",
      "0: 640x640 3 persons, 1 remote, 172.0ms\n",
      "Speed: 2.4ms preprocess, 172.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Estimated scale factor: 0.390\n",
      "Valid depth correspondences: 4508\n",
      "Scale:  0.3901980722007522\n",
      "13 !!! 57\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289544.184151 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289544.185474 5078987 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 4508\n",
      "Scale:  0.9999999524386081\n",
      "13 !!! 58\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289544.662956 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289544.663907 5078993 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 4508\n",
      "Scale:  1.0000000417645818\n",
      "13 !!! 59\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n",
      "670700360500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289545.147998 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289545.149180 5079005 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Metric depth range: 2.5063558 → 19.982416\n",
      "\n",
      "0: 640x640 3 persons, 160.5ms\n",
      "Speed: 2.5ms preprocess, 160.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Estimated scale factor: 0.423\n",
      "Valid depth correspondences: 4538\n",
      "Scale:  0.42286470075673277\n",
      "14 !!! 60\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289547.213500 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289547.214533 5079051 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 4538\n",
      "Scale:  1.0000000270498288\n",
      "14 !!! 61\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289547.698734 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289547.699892 5079061 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 4538\n",
      "Scale:  1.0000000270498288\n",
      "14 !!! 62\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n",
      "670800361087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289548.184411 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289548.185569 5079069 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Metric depth range: 3.2084086 → 19.985285\n",
      "\n",
      "0: 640x640 3 persons, 155.7ms\n",
      "Speed: 2.4ms preprocess, 155.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Estimated scale factor: 0.464\n",
      "Valid depth correspondences: 4547\n",
      "Scale:  0.46434376455144644\n",
      "15 !!! 63\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289550.387402 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289550.388868 5079102 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 4547\n",
      "Scale:  1.0000000310460289\n",
      "15 !!! 64\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289550.865573 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289550.866994 5079118 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 4547\n",
      "Scale:  1.0000000310460289\n",
      "15 !!! 65\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n",
      "670900361712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289551.348576 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289551.350082 5079126 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Metric depth range: 3.5180275 → 19.980364\n",
      "\n",
      "0: 640x640 3 persons, 171.1ms\n",
      "Speed: 2.6ms preprocess, 171.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Estimated scale factor: 0.497\n",
      "Valid depth correspondences: 4498\n",
      "Scale:  0.4966682552221323\n",
      "16 !!! 66\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289553.537834 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289553.539130 5079162 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 4498\n",
      "Scale:  0.9999999742994177\n",
      "16 !!! 67\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289554.014793 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289554.016023 5079181 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 4498\n",
      "Scale:  0.9999999742994177\n",
      "16 !!! 68\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n",
      "671000358587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289554.497942 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289554.499359 5079273 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Metric depth range: 3.5224295 → 19.984037\n",
      "\n",
      "0: 640x640 3 persons, 159.5ms\n",
      "Speed: 4.0ms preprocess, 159.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Estimated scale factor: 0.503\n",
      "Valid depth correspondences: 4481\n",
      "Scale:  0.5029507442968488\n",
      "17 !!! 69\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289556.715366 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289556.716558 5079307 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 4481\n",
      "Scale:  1.000000010241517\n",
      "17 !!! 70\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289557.188389 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289557.189846 5079321 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 4481\n",
      "Scale:  1.000000010241517\n",
      "17 !!! 71\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n",
      "671100359037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289557.652270 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289557.653640 5079329 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Metric depth range: 3.4897614 → 19.980528\n",
      "\n",
      "0: 640x640 1 person, 161.2ms\n",
      "Speed: 2.3ms preprocess, 161.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Estimated scale factor: 0.516\n",
      "Valid depth correspondences: 4488\n",
      "Scale:  0.5158925198313693\n",
      "18 !!! 72\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n",
      "671200361675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289559.844975 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289559.846062 5079379 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Metric depth range: 3.4778895 → 19.982565\n",
      "\n",
      "0: 640x640 1 person, 196.1ms\n",
      "Speed: 2.3ms preprocess, 196.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Estimated scale factor: 0.519\n",
      "Valid depth correspondences: 4488\n",
      "Scale:  0.5191003385661865\n",
      "19 !!! 73\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n",
      "671300354087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289562.209138 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289562.210273 5079406 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Metric depth range: 3.4972875 → 19.97557\n",
      "\n",
      "0: 640x640 3 persons, 1 bench, 197.9ms\n",
      "Speed: 2.6ms preprocess, 197.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Estimated scale factor: 0.515\n",
      "Valid depth correspondences: 4502\n",
      "Scale:  0.5151991962406576\n",
      "20 !!! 74\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289564.511781 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289564.512925 5079439 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 4502\n",
      "Scale:  1.0000000120978116\n",
      "20 !!! 75\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289564.994317 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289564.995540 5079452 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 4502\n",
      "Scale:  1.0000000120978116\n",
      "20 !!! 76\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n",
      "671400362412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289565.470466 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289565.471751 5079463 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Metric depth range: 3.3851166 → 19.964231\n",
      "\n",
      "0: 640x640 3 persons, 1 bench, 169.2ms\n",
      "Speed: 2.5ms preprocess, 169.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Estimated scale factor: 0.527\n",
      "Valid depth correspondences: 4532\n",
      "Scale:  0.5271766261934188\n",
      "21 !!! 77\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289567.836487 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289567.837697 5079515 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 4532\n",
      "Scale:  1.0000000591599965\n",
      "21 !!! 78\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289568.313772 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289568.314951 5079526 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 4532\n",
      "Scale:  1.0000000591599965\n",
      "21 !!! 79\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n",
      "671500358037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289568.787936 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289568.789205 5079537 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Metric depth range: 3.3049977 → 19.970793\n",
      "\n",
      "0: 640x640 4 persons, 1 bench, 192.4ms\n",
      "Speed: 2.8ms preprocess, 192.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Estimated scale factor: 0.530\n",
      "Valid depth correspondences: 4586\n",
      "Scale:  0.529522950528335\n",
      "22 !!! 80\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289571.129936 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289571.131055 5079580 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 4586\n",
      "Scale:  0.9999999698380293\n",
      "22 !!! 81\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289571.605898 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289571.607148 5079593 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 4586\n",
      "Scale:  1.0000000638919824\n",
      "22 !!! 82\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289572.086967 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289572.088378 5079618 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 4586\n",
      "Scale:  0.9999999313994826\n",
      "22 !!! 83\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "671600352050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289572.611960 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289572.613114 5079639 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Metric depth range: 3.3627698 → 19.97852\n",
      "\n",
      "0: 640x640 3 persons, 1 bench, 186.4ms\n",
      "Speed: 3.3ms preprocess, 186.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Estimated scale factor: 0.530\n",
      "Valid depth correspondences: 4639\n",
      "Scale:  0.5300981723113906\n",
      "23 !!! 84\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289574.966223 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289574.967351 5079669 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 4639\n",
      "Scale:  0.9999999471067438\n",
      "23 !!! 85\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289575.445680 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289575.446892 5079678 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 4639\n",
      "Scale:  1.000000015711011\n",
      "23 !!! 86\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n",
      "671700362500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289575.914666 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289575.916245 5079696 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Metric depth range: 3.393225 → 19.968407\n",
      "\n",
      "0: 640x640 3 persons, 1 bench, 170.0ms\n",
      "Speed: 2.5ms preprocess, 170.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Estimated scale factor: 0.546\n",
      "Valid depth correspondences: 4668\n",
      "Scale:  0.546433703120374\n",
      "24 !!! 87\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289578.228300 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289578.230111 5079735 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 4668\n",
      "Scale:  1.0000000331568042\n",
      "24 !!! 88\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289578.714512 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289578.715553 5079746 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 4668\n",
      "Scale:  1.0000000331568042\n",
      "24 !!! 89\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n",
      "671800355675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289579.231652 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289579.232769 5079756 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Metric depth range: 3.4019327 → 19.972404\n",
      "\n",
      "0: 640x640 3 persons, 1 bench, 177.8ms\n",
      "Speed: 2.8ms preprocess, 177.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Estimated scale factor: 0.533\n",
      "Valid depth correspondences: 4693\n",
      "Scale:  0.5332774096469487\n",
      "25 !!! 90\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289581.480892 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289581.482538 5079780 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 4693\n",
      "Scale:  1.0000000240001208\n",
      "25 !!! 91\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289581.964307 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289581.966073 5079794 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 4693\n",
      "Scale:  1.0000000240001208\n",
      "25 !!! 92\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n",
      "671900356250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289582.503063 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289582.504205 5079807 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Metric depth range: 3.4344504 → 19.97014\n",
      "\n",
      "0: 640x640 4 persons, 1 bench, 166.4ms\n",
      "Speed: 2.5ms preprocess, 166.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Estimated scale factor: 0.496\n",
      "Valid depth correspondences: 4722\n",
      "Scale:  0.4956956454822472\n",
      "26 !!! 93\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289584.714680 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289584.716064 5079839 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 4722\n",
      "Scale:  0.9999999733803637\n",
      "26 !!! 94\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289585.199934 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289585.201300 5079851 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 4722\n",
      "Scale:  0.9999999733803637\n",
      "26 !!! 95\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289585.729339 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289585.730503 5079864 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 4722\n",
      "Scale:  0.9999999733803637\n",
      "26 !!! 96\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n",
      "672000360587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289586.194985 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289586.196320 5079879 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Metric depth range: 3.4686348 → 19.966585\n",
      "\n",
      "0: 640x640 3 persons, 1 bench, 174.5ms\n",
      "Speed: 4.1ms preprocess, 174.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Estimated scale factor: 0.488\n",
      "Valid depth correspondences: 4755\n",
      "Scale:  0.4881890908801511\n",
      "27 !!! 97\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289588.405299 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289588.406484 5079921 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 4755\n",
      "Scale:  1.0000000023614464\n",
      "27 !!! 98\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289588.883088 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289588.884573 5079935 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 4755\n",
      "Scale:  1.0000000023614464\n",
      "27 !!! 99\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n",
      "672100396087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289589.406488 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289589.407488 5079947 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Metric depth range: 3.3485396 → 19.975477\n",
      "\n",
      "0: 640x640 3 persons, 1 bench, 182.0ms\n",
      "Speed: 2.5ms preprocess, 182.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Estimated scale factor: 0.459\n",
      "Valid depth correspondences: 4819\n",
      "Scale:  0.459074174074607\n",
      "28 !!! 100\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289591.652520 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289591.653638 5079975 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 4819\n",
      "Scale:  0.9999999917054769\n",
      "28 !!! 101\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289592.138900 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289592.140037 5079988 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 4819\n",
      "Scale:  0.9999999917054769\n",
      "28 !!! 102\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n",
      "672200357875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289592.655161 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289592.657102 5080004 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Metric depth range: 3.041755 → 19.961624\n",
      "\n",
      "0: 640x640 3 persons, 1 bench, 156.8ms\n",
      "Speed: 2.5ms preprocess, 156.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Estimated scale factor: 0.447\n",
      "Valid depth correspondences: 4875\n",
      "Scale:  0.446679563165815\n",
      "29 !!! 103\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289594.818012 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289594.819818 5080046 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 4875\n",
      "Scale:  1.0000000182773165\n",
      "29 !!! 104\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289595.295656 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289595.297508 5080054 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 4875\n",
      "Scale:  1.0000000182773165\n",
      "29 !!! 105\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n",
      "672300396250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289595.810965 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289595.812010 5080073 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Metric depth range: 2.9967072 → 19.967358\n",
      "\n",
      "0: 640x640 3 persons, 1 bench, 154.1ms\n",
      "Speed: 2.8ms preprocess, 154.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Estimated scale factor: 0.436\n",
      "Valid depth correspondences: 4937\n",
      "Scale:  0.4359842257216438\n",
      "30 !!! 106\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289598.045796 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289598.047235 5080104 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 4937\n",
      "Scale:  1.0000000233672588\n",
      "30 !!! 107\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289598.521137 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289598.522177 5080114 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 4937\n",
      "Scale:  1.0000000233672588\n",
      "30 !!! 108\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n",
      "672400361750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289599.043937 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289599.045683 5080128 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Metric depth range: 3.03427 → 19.948507\n",
      "\n",
      "0: 640x640 3 persons, 1 bench, 157.6ms\n",
      "Speed: 2.6ms preprocess, 157.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Estimated scale factor: 0.438\n",
      "Valid depth correspondences: 4964\n",
      "Scale:  0.43789427187948726\n",
      "31 !!! 109\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289601.221292 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289601.222914 5080153 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 4964\n",
      "Scale:  0.9999999615505775\n",
      "31 !!! 110\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289601.709686 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289601.710814 5080162 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 4964\n",
      "Scale:  1.0000000288782167\n",
      "31 !!! 111\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n",
      "672500359375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289602.231660 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289602.232956 5080175 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Metric depth range: 2.9860504 → 19.970198\n",
      "\n",
      "0: 640x640 5 persons, 1 bench, 171.9ms\n",
      "Speed: 2.4ms preprocess, 171.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Estimated scale factor: 0.449\n",
      "Valid depth correspondences: 4986\n",
      "Scale:  0.44942179933007076\n",
      "32 !!! 112\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289604.311467 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289604.312624 5080195 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 4986\n",
      "Scale:  1.0000000128544357\n",
      "32 !!! 113\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289604.807161 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289604.808254 5080206 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 4986\n",
      "Scale:  1.0000000128544357\n",
      "32 !!! 114\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289605.323008 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289605.323996 5080215 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 4986\n",
      "Scale:  1.0000000128544357\n",
      "32 !!! 115\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289605.798846 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289605.799881 5080226 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 4986\n",
      "Scale:  1.0000000128544357\n",
      "32 !!! 116\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "672600356037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289606.293381 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289606.294474 5080240 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Metric depth range: 3.5247998 → 19.96695\n",
      "\n",
      "0: 640x640 5 persons, 1 bench, 162.3ms\n",
      "Speed: 2.7ms preprocess, 162.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Estimated scale factor: 0.419\n",
      "Valid depth correspondences: 5046\n",
      "Scale:  0.4187057045361662\n",
      "33 !!! 117\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289608.371715 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289608.372786 5080278 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 5046\n",
      "Scale:  1.0000000173098926\n",
      "33 !!! 118\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289608.885173 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289608.886397 5080288 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 5046\n",
      "Scale:  1.0000000173098926\n",
      "33 !!! 119\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289609.398535 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289609.399643 5080301 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 5046\n",
      "Scale:  1.0000000173098926\n",
      "33 !!! 120\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289609.881985 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289609.883173 5080315 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 5046\n",
      "Scale:  1.0000000173098926\n",
      "33 !!! 121\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n",
      "672700363125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289610.342041 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289610.343153 5080325 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Metric depth range: 3.6393483 → 19.951307\n",
      "\n",
      "0: 640x640 5 persons, 1 bench, 159.4ms\n",
      "Speed: 2.7ms preprocess, 159.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Estimated scale factor: 0.392\n",
      "Valid depth correspondences: 5098\n",
      "Scale:  0.3915142149466915\n",
      "34 !!! 122\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289612.388264 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289612.389857 5080349 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 5098\n",
      "Scale:  1.0000000254690558\n",
      "34 !!! 123\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289612.867824 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289612.868962 5080359 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 5098\n",
      "Scale:  1.0000000254690558\n",
      "34 !!! 124\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289613.387222 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289613.388225 5080372 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 5098\n",
      "Scale:  1.0000000254690558\n",
      "34 !!! 125\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289613.866072 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289613.867336 5080397 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 5098\n",
      "Scale:  1.0000000254690558\n",
      "34 !!! 126\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n",
      "672800354675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289614.351663 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289614.353115 5080409 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Metric depth range: 3.5025272 → 19.942501\n",
      "\n",
      "0: 640x640 5 persons, 1 chair, 166.0ms\n",
      "Speed: 2.4ms preprocess, 166.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Estimated scale factor: 0.403\n",
      "Valid depth correspondences: 5166\n",
      "Scale:  0.4033566268885566\n",
      "35 !!! 127\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289616.543134 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289616.544220 5080441 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 5166\n",
      "Scale:  0.9999999595293287\n",
      "35 !!! 128\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289617.023017 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289617.024511 5080453 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 5166\n",
      "Scale:  1.0000000338752058\n",
      "35 !!! 129\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289617.546112 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289617.547584 5080468 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 5166\n",
      "Scale:  1.0000000338752058\n",
      "35 !!! 130\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289618.061930 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289618.063106 5080477 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 5166\n",
      "Scale:  1.0000000338752058\n",
      "35 !!! 131\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "672900353875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289618.556944 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289618.558077 5080490 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Metric depth range: 3.5336943 → 19.942053\n",
      "\n",
      "0: 640x640 5 persons, 1 bench, 190.1ms\n",
      "Speed: 2.7ms preprocess, 190.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Estimated scale factor: 0.377\n",
      "Valid depth correspondences: 5252\n",
      "Scale:  0.37671851529653716\n",
      "36 !!! 132\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289620.748728 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289620.749918 5080527 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 5252\n",
      "Scale:  0.9999999723451131\n",
      "36 !!! 133\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289621.241327 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289621.242554 5080543 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 5252\n",
      "Scale:  0.9999999723451131\n",
      "36 !!! 134\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289621.790574 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289621.791858 5080562 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 5252\n",
      "Scale:  0.9999999723451131\n",
      "36 !!! 135\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289622.278297 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289622.279540 5080577 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 5252\n",
      "Scale:  0.9999999723451131\n",
      "36 !!! 136\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "673000361212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289622.765323 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289622.766459 5080593 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Metric depth range: 3.5587366 → 19.943247\n",
      "\n",
      "0: 640x640 5 persons, 1 chair, 161.6ms\n",
      "Speed: 2.3ms preprocess, 161.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Estimated scale factor: 0.412\n",
      "Valid depth correspondences: 5337\n",
      "Scale:  0.41238222273898806\n",
      "37 !!! 137\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289625.054883 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289625.056212 5080625 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 5337\n",
      "Scale:  0.9999999785943822\n",
      "37 !!! 138\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289625.535742 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289625.536932 5080636 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 5337\n",
      "Scale:  0.9999999785943822\n",
      "37 !!! 139\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289626.056573 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289626.057692 5080649 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 5337\n",
      "Scale:  0.9999999785943822\n",
      "37 !!! 140\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289626.561272 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289626.562488 5080663 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 5337\n",
      "Scale:  0.9999999785943822\n",
      "37 !!! 141\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n",
      "673100361800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289627.045376 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289627.047103 5080675 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Metric depth range: 3.6078963 → 19.930162\n",
      "\n",
      "0: 640x640 5 persons, 1 chair, 167.6ms\n",
      "Speed: 2.4ms preprocess, 167.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Estimated scale factor: 0.393\n",
      "Valid depth correspondences: 5429\n",
      "Scale:  0.3930281195023623\n",
      "38 !!! 142\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289629.193889 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289629.195009 5080708 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 5429\n",
      "Scale:  1.000000005679474\n",
      "38 !!! 143\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289629.663498 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289629.665332 5080721 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 5429\n",
      "Scale:  1.000000005679474\n",
      "38 !!! 144\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289630.183370 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289630.184461 5080745 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 5429\n",
      "Scale:  1.000000005679474\n",
      "38 !!! 145\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289630.687392 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289630.688531 5080757 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 5429\n",
      "Scale:  1.000000005679474\n",
      "38 !!! 146\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n",
      "673200362375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289631.187698 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289631.188816 5080770 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Metric depth range: 3.56417 → 19.934555\n",
      "\n",
      "0: 640x640 6 persons, 1 bench, 166.1ms\n",
      "Speed: 3.2ms preprocess, 166.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Estimated scale factor: 0.410\n",
      "Valid depth correspondences: 5475\n",
      "Scale:  0.4101749195161829\n",
      "39 !!! 147\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289633.356903 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289633.358215 5080808 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 5475\n",
      "Scale:  1.0000000389181383\n",
      "39 !!! 148\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289633.820379 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289633.821612 5080821 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 5475\n",
      "Scale:  1.0000000389181383\n",
      "39 !!! 149\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289634.336333 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289634.337709 5080835 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 5475\n",
      "Scale:  1.0000000389181383\n",
      "39 !!! 150\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289634.803691 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289634.804660 5080848 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 5475\n",
      "Scale:  1.0000000389181383\n",
      "39 !!! 151\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289635.279356 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289635.280297 5080859 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 5475\n",
      "Scale:  1.0000000389181383\n",
      "39 !!! 152\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n",
      "673300363000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289635.768136 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289635.769396 5080870 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Metric depth range: 3.4804604 → 19.892797\n",
      "\n",
      "0: 640x640 3 persons, 1 bench, 163.6ms\n",
      "Speed: 2.6ms preprocess, 163.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Estimated scale factor: 0.412\n",
      "Valid depth correspondences: 5520\n",
      "Scale:  0.4119049041449755\n",
      "40 !!! 153\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289637.887847 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289637.889835 5080898 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 5520\n",
      "Scale:  1.0000000348371203\n",
      "40 !!! 154\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289638.371535 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289638.373526 5080915 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 5520\n",
      "Scale:  1.0000000348371203\n",
      "40 !!! 155\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "673400359875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289638.889996 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289638.891094 5080925 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Metric depth range: 3.5438838 → 19.902058\n",
      "\n",
      "0: 640x640 5 persons, 1 bench, 157.3ms\n",
      "Speed: 2.3ms preprocess, 157.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Estimated scale factor: 0.397\n",
      "Valid depth correspondences: 5550\n",
      "Scale:  0.39653749502223923\n",
      "41 !!! 156\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289641.044917 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289641.046035 5080959 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 5550\n",
      "Scale:  1.0000000351203153\n",
      "41 !!! 157\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289641.517035 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289641.518257 5080970 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 5550\n",
      "Scale:  1.0000000351203153\n",
      "41 !!! 158\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289642.042506 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289642.044173 5080983 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 5550\n",
      "Scale:  1.0000000351203153\n",
      "41 !!! 159\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289642.529424 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289642.530629 5080996 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 5550\n",
      "Scale:  1.0000000351203153\n",
      "41 !!! 160\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "673500355462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289643.007627 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289643.008820 5081006 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Metric depth range: 3.5390716 → 19.881388\n",
      "\n",
      "0: 640x640 4 persons, 1 chair, 156.4ms\n",
      "Speed: 2.4ms preprocess, 156.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Estimated scale factor: 0.378\n",
      "Valid depth correspondences: 5630\n",
      "Scale:  0.3780976552028905\n",
      "42 !!! 161\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289645.105301 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289645.106600 5081035 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 5630\n",
      "Scale:  1.0000000165642002\n",
      "42 !!! 162\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289645.582463 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289645.584006 5081046 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 5630\n",
      "Scale:  1.0000000165642002\n",
      "42 !!! 163\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289646.115370 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289646.116315 5081063 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 5630\n",
      "Scale:  1.0000000165642002\n",
      "42 !!! 164\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "673600357675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289646.610285 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289646.611763 5081076 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Metric depth range: 3.5402336 → 19.910025\n",
      "\n",
      "0: 640x640 5 persons, 1 chair, 161.5ms\n",
      "Speed: 2.4ms preprocess, 161.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Estimated scale factor: 0.345\n",
      "Valid depth correspondences: 5692\n",
      "Scale:  0.34485632624793777\n",
      "43 !!! 165\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289648.748941 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289648.749990 5081107 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 5692\n",
      "Scale:  1.000000013265208\n",
      "43 !!! 166\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289649.241858 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289649.242906 5081116 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 5692\n",
      "Scale:  1.000000013265208\n",
      "43 !!! 167\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289649.761895 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289649.763317 5081128 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 5692\n",
      "Scale:  1.000000013265208\n",
      "43 !!! 168\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289650.244692 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289650.245725 5081144 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 5692\n",
      "Scale:  1.000000013265208\n",
      "43 !!! 169\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n",
      "673700360250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289650.726527 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289650.727709 5081157 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Metric depth range: 3.5404541 → 19.870905\n",
      "\n",
      "0: 640x640 3 persons, 1 chair, 158.4ms\n",
      "Speed: 2.7ms preprocess, 158.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Estimated scale factor: 0.328\n",
      "Valid depth correspondences: 5779\n",
      "Scale:  0.3282253973038397\n",
      "44 !!! 170\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289652.898009 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289652.899007 5081202 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 5779\n",
      "Scale:  1.0000000027045277\n",
      "44 !!! 171\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289653.396152 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289653.397369 5081214 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 5779\n",
      "Scale:  1.0000000027045277\n",
      "44 !!! 172\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n",
      "673800379375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289653.923154 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289653.924315 5081234 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Metric depth range: 3.5799935 → 19.920403\n",
      "\n",
      "0: 640x640 5 persons, 1 chair, 1 clock, 156.5ms\n",
      "Speed: 2.5ms preprocess, 156.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Estimated scale factor: 0.326\n",
      "Valid depth correspondences: 5813\n",
      "Scale:  0.325735232272004\n",
      "45 !!! 173\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289656.189126 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289656.190862 5081289 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 5813\n",
      "Scale:  0.9999999351590815\n",
      "45 !!! 174\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289656.668968 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289656.669929 5081301 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 5813\n",
      "Scale:  1.0000000134428826\n",
      "45 !!! 175\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289657.194799 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289657.196009 5081313 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 5813\n",
      "Scale:  1.0000000134428826\n",
      "45 !!! 176\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289657.671553 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289657.672764 5081328 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 5813\n",
      "Scale:  1.0000000134428826\n",
      "45 !!! 177\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "673900363587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289658.209148 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289658.210421 5081343 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Metric depth range: 3.6157482 → 19.88714\n",
      "\n",
      "0: 640x640 5 persons, 1 chair, 1 clock, 168.2ms\n",
      "Speed: 2.8ms preprocess, 168.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Estimated scale factor: 0.341\n",
      "Valid depth correspondences: 5859\n",
      "Scale:  0.3414312785909575\n",
      "46 !!! 178\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289660.401792 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289660.403105 5081372 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 5859\n",
      "Scale:  0.9999999700393384\n",
      "46 !!! 179\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289660.897623 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289660.898579 5081387 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 5859\n",
      "Scale:  1.0000000441044512\n",
      "46 !!! 180\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289661.427445 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289661.428601 5081401 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 5859\n",
      "Scale:  1.0000000441044512\n",
      "46 !!! 181\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289661.905448 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289661.906475 5081412 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 5859\n",
      "Scale:  1.0000000441044512\n",
      "46 !!! 182\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "674000358337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289662.433769 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289662.434831 5081425 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Metric depth range: 3.5544977 → 19.811256\n",
      "\n",
      "0: 640x640 5 persons, 2 chairs, 162.8ms\n",
      "Speed: 2.3ms preprocess, 162.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Estimated scale factor: 0.334\n",
      "Valid depth correspondences: 5956\n",
      "Scale:  0.33362553822534335\n",
      "47 !!! 183\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289664.627393 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289664.628551 5081459 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 5956\n",
      "Scale:  1.0000000503196647\n",
      "47 !!! 184\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289665.140099 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289665.141260 5081476 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 5956\n",
      "Scale:  1.0000000503196647\n",
      "47 !!! 185\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289665.668409 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289665.670059 5081492 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 5956\n",
      "Scale:  1.0000000503196647\n",
      "47 !!! 186\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289666.148296 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289666.149428 5081512 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 5956\n",
      "Scale:  1.0000000503196647\n",
      "47 !!! 187\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n",
      "674100356037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289666.635499 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289666.636625 5081524 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Metric depth range: 1.6061566 → 19.8939\n",
      "\n",
      "0: 640x640 5 persons, 2 chairs, 163.2ms\n",
      "Speed: 2.5ms preprocess, 163.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Estimated scale factor: 0.314\n",
      "Valid depth correspondences: 6050\n",
      "Scale:  0.3144393648567966\n",
      "48 !!! 188\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289668.916148 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289668.917692 5081562 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 6050\n",
      "Scale:  1.0000000313131623\n",
      "48 !!! 189\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289669.407105 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289669.408246 5081575 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 6050\n",
      "Scale:  1.0000000313131623\n",
      "48 !!! 190\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289669.934850 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289669.935808 5081587 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 6050\n",
      "Scale:  1.0000000313131623\n",
      "48 !!! 191\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289670.419116 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289670.420689 5081600 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 6050\n",
      "Scale:  1.0000000313131623\n",
      "48 !!! 192\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n",
      "674200359212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289670.909799 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289670.910817 5081612 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Metric depth range: 2.969885 → 19.90716\n",
      "\n",
      "0: 640x640 4 persons, 2 chairs, 165.7ms\n",
      "Speed: 3.1ms preprocess, 165.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Estimated scale factor: 0.318\n",
      "Valid depth correspondences: 6208\n",
      "Scale:  0.3177407278751915\n",
      "49 !!! 193\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289673.205943 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289673.207851 5081654 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 6208\n",
      "Scale:  0.9999999435293833\n",
      "49 !!! 194\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289673.708344 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289673.709404 5081671 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 6208\n",
      "Scale:  1.0000000196287009\n",
      "49 !!! 195\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289674.233112 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289674.234464 5081687 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 6208\n",
      "Scale:  1.0000000196287009\n",
      "49 !!! 196\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n",
      "674300359800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289674.708740 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289674.709895 5081705 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Metric depth range: 2.7782369 → 19.71571\n",
      "\n",
      "0: 640x640 5 persons, 2 chairs, 185.3ms\n",
      "Speed: 2.8ms preprocess, 185.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Estimated scale factor: 0.300\n",
      "Valid depth correspondences: 6417\n",
      "Scale:  0.29972091424504754\n",
      "50 !!! 197\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289676.938603 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289676.939883 5081741 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 6417\n",
      "Scale:  1.0000000210382751\n",
      "50 !!! 198\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289677.431809 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289677.433189 5081756 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 6417\n",
      "Scale:  1.0000000210382751\n",
      "50 !!! 199\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289677.979737 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289677.981009 5081770 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 6417\n",
      "Scale:  1.0000000210382751\n",
      "50 !!! 200\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289678.458996 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289678.460051 5081785 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 6417\n",
      "Scale:  1.0000000210382751\n",
      "50 !!! 201\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "674400360425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289678.999110 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289679.000253 5081796 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Metric depth range: 2.6066709 → 19.832932\n",
      "\n",
      "0: 640x640 5 persons, 2 chairs, 1 remote, 180.8ms\n",
      "Speed: 2.8ms preprocess, 180.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Estimated scale factor: 0.280\n",
      "Valid depth correspondences: 6502\n",
      "Scale:  0.28007809848834675\n",
      "51 !!! 202\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289681.225358 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289681.226831 5081834 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 6502\n",
      "Scale:  0.9999999287104895\n",
      "51 !!! 203\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289681.703587 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289681.705475 5081847 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 6502\n",
      "Scale:  1.0000000070792956\n",
      "51 !!! 204\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289682.237460 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289682.238689 5081862 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 6502\n",
      "Scale:  1.0000000070792956\n",
      "51 !!! 205\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289682.730548 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289682.732002 5081880 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 6502\n",
      "Scale:  1.0000000070792956\n",
      "51 !!! 206\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n",
      "674500361000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289683.333210 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289683.334333 5081894 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Metric depth range: 2.5441515 → 20.064459\n",
      "\n",
      "0: 640x640 4 persons, 1 chair, 1 remote, 174.6ms\n",
      "Speed: 2.9ms preprocess, 174.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Estimated scale factor: 0.288\n",
      "Valid depth correspondences: 6555\n",
      "Scale:  0.2880435034005702\n",
      "52 !!! 207\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289685.567714 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289685.568732 5081939 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 6555\n",
      "Scale:  0.9999999955853618\n",
      "52 !!! 208\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289686.065077 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289686.066631 5081969 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 6555\n",
      "Scale:  0.9999999955853618\n",
      "52 !!! 209\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289686.600628 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289686.602236 5081983 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 6555\n",
      "Scale:  0.9999999955853618\n",
      "52 !!! 210\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n",
      "674600361625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289687.089945 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289687.090912 5082001 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Metric depth range: 2.334739 → 19.950224\n",
      "\n",
      "0: 640x640 6 persons, 1 chair, 1 remote, 1 clock, 183.9ms\n",
      "Speed: 2.1ms preprocess, 183.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Estimated scale factor: 0.282\n",
      "Valid depth correspondences: 6596\n",
      "Scale:  0.2818294154374409\n",
      "53 !!! 211\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289689.299841 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289689.301597 5082031 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 6596\n",
      "Scale:  1.00000000392826\n",
      "53 !!! 212\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289689.775813 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289689.776938 5082043 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 6596\n",
      "Scale:  1.00000000392826\n",
      "53 !!! 213\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289690.307729 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289690.308749 5082079 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 6596\n",
      "Scale:  1.00000000392826\n",
      "53 !!! 214\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289690.807291 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289690.809485 5082125 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 6596\n",
      "Scale:  1.00000000392826\n",
      "53 !!! 215\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289691.362557 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289691.363807 5082182 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 6596\n",
      "Scale:  1.00000000392826\n",
      "53 !!! 216\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "674700357462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289691.895474 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289691.896555 5082209 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Metric depth range: 2.4216685 → 19.887026\n",
      "\n",
      "0: 640x640 6 persons, 2 chairs, 1 remote, 1 clock, 165.9ms\n",
      "Speed: 3.5ms preprocess, 165.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Estimated scale factor: 0.269\n",
      "Valid depth correspondences: 6599\n",
      "Scale:  0.26895375190450443\n",
      "54 !!! 217\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289694.158325 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289694.159584 5082267 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 6599\n",
      "Scale:  1.0000000670251055\n",
      "54 !!! 218\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289694.645096 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289694.646235 5082281 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 6599\n",
      "Scale:  0.9999999810648645\n",
      "54 !!! 219\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289695.171751 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289695.172751 5082310 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 6599\n",
      "Scale:  0.9999999810648645\n",
      "54 !!! 220\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289695.645984 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289695.647097 5082328 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 6599\n",
      "Scale:  0.9999999810648645\n",
      "54 !!! 221\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289696.186494 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289696.187575 5082345 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 6599\n",
      "Scale:  0.9999999810648645\n",
      "54 !!! 222\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n",
      "674800355087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289696.787946 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289696.788997 5082357 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Metric depth range: 2.4072044 → 20.030916\n",
      "\n",
      "0: 640x640 5 persons, 2 chairs, 1 remote, 162.4ms\n",
      "Speed: 2.4ms preprocess, 162.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Estimated scale factor: 0.251\n",
      "Valid depth correspondences: 6628\n",
      "Scale:  0.2514267384942796\n",
      "55 !!! 223\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289699.035003 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289699.036704 5082402 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 6628\n",
      "Scale:  1.0000000495654744\n",
      "55 !!! 224\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289699.514008 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289699.515267 5082419 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 6628\n",
      "Scale:  1.0000000495654744\n",
      "55 !!! 225\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289700.048514 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289700.049737 5082433 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 6628\n",
      "Scale:  1.0000000495654744\n",
      "55 !!! 226\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289700.532694 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289700.533728 5082448 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 6628\n",
      "Scale:  1.0000000495654744\n",
      "55 !!! 227\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n",
      "674900361087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289701.137949 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289701.139618 5082473 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Metric depth range: 2.5297728 → 20.084661\n",
      "\n",
      "0: 640x640 5 persons, 2 chairs, 1 remote, 170.5ms\n",
      "Speed: 2.8ms preprocess, 170.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Estimated scale factor: 0.238\n",
      "Valid depth correspondences: 6667\n",
      "Scale:  0.2383665811297021\n",
      "56 !!! 228\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289703.606649 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289703.607746 5082559 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 6667\n",
      "Scale:  1.0000000500464952\n",
      "56 !!! 229\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289704.106367 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289704.107582 5082569 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 6667\n",
      "Scale:  1.0000000500464952\n",
      "56 !!! 230\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289704.636798 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289704.637920 5082583 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 6667\n",
      "Scale:  1.0000000500464952\n",
      "56 !!! 231\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289705.234107 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289705.235445 5082606 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 6667\n",
      "Scale:  1.0000000500464952\n",
      "56 !!! 232\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "675000361037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289705.729595 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289705.730690 5082617 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Metric depth range: 2.7382247 → 19.92227\n",
      "\n",
      "0: 640x640 5 persons, 2 chairs, 1 remote, 1 clock, 179.3ms\n",
      "Speed: 3.0ms preprocess, 179.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Estimated scale factor: 0.238\n",
      "Valid depth correspondences: 6726\n",
      "Scale:  0.23829312184218876\n",
      "57 !!! 233\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289708.068765 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289708.070257 5082668 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 6726\n",
      "Scale:  0.9999999714644369\n",
      "57 !!! 234\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289708.547278 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289708.549109 5082681 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 6726\n",
      "Scale:  0.9999999714644369\n",
      "57 !!! 235\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289709.074815 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289709.076699 5082697 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 6726\n",
      "Scale:  0.9999999714644369\n",
      "57 !!! 236\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289709.667496 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289709.669228 5082710 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 6726\n",
      "Scale:  0.9999999714644369\n",
      "57 !!! 237\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "675100358337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289710.216334 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289710.217510 5082722 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Metric depth range: 2.7185965 → 19.878555\n",
      "\n",
      "0: 640x640 4 persons, 2 chairs, 1 remote, 1 clock, 160.4ms\n",
      "Speed: 3.6ms preprocess, 160.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Estimated scale factor: 0.222\n",
      "Valid depth correspondences: 6737\n",
      "Scale:  0.2222948414297345\n",
      "58 !!! 238\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289712.502621 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289712.504308 5082853 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 6737\n",
      "Scale:  1.0000000012654033\n",
      "58 !!! 239\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289713.007835 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289713.009375 5082868 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 6737\n",
      "Scale:  1.0000000012654033\n",
      "58 !!! 240\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289713.667941 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289713.669071 5082912 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 6737\n",
      "Scale:  1.0000000012654033\n",
      "58 !!! 241\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n",
      "675200364050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289714.329060 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289714.330578 5083078 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Metric depth range: 1.8857608 → 19.943895\n",
      "\n",
      "0: 640x640 5 persons, 2 chairs, 1 clock, 232.7ms\n",
      "Speed: 4.4ms preprocess, 232.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Estimated scale factor: 0.223\n",
      "Valid depth correspondences: 6683\n",
      "Scale:  0.22268271925935054\n",
      "59 !!! 242\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289717.631043 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289717.632343 5083467 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 6683\n",
      "Scale:  1.0000000484891514\n",
      "59 !!! 243\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289718.138065 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289718.139501 5083506 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 6683\n",
      "Scale:  1.0000000484891514\n",
      "59 !!! 244\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289718.739557 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289718.740807 5083520 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 6683\n",
      "Scale:  1.0000000484891514\n",
      "59 !!! 245\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289719.278730 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289719.280275 5083534 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 6683\n",
      "Scale:  1.0000000484891514\n",
      "59 !!! 246\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n",
      "675300360925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289719.754408 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289719.755788 5083546 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Metric depth range: 1.471121 → 20.024654\n",
      "\n",
      "0: 640x640 4 persons, 2 chairs, 1 clock, 159.9ms\n",
      "Speed: 2.4ms preprocess, 159.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Estimated scale factor: 0.224\n",
      "Valid depth correspondences: 6639\n",
      "Scale:  0.2238236085327423\n",
      "60 !!! 247\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289721.996969 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289721.998156 5083592 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 6639\n",
      "Scale:  1.0000000005841037\n",
      "60 !!! 248\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289722.475639 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289722.476938 5083609 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 6639\n",
      "Scale:  1.0000000005841037\n",
      "60 !!! 249\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289723.074357 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289723.075343 5083627 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 6639\n",
      "Scale:  1.0000000005841037\n",
      "60 !!! 250\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n",
      "675400355250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289723.613714 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289723.614918 5083639 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Metric depth range: 2.5929515 → 19.993376\n",
      "\n",
      "0: 640x640 4 persons, 2 chairs, 1 clock, 174.2ms\n",
      "Speed: 3.4ms preprocess, 174.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Estimated scale factor: 0.228\n",
      "Valid depth correspondences: 6645\n",
      "Scale:  0.22844210915718094\n",
      "61 !!! 251\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289725.762037 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289725.763800 5083673 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 6645\n",
      "Scale:  1.0000000428855729\n",
      "61 !!! 252\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289726.247540 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289726.248768 5083685 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 6645\n",
      "Scale:  1.0000000428855729\n",
      "61 !!! 253\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289726.840931 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289726.841918 5083701 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 6645\n",
      "Scale:  1.0000000428855729\n",
      "61 !!! 254\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "675500355837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289727.379263 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289727.380474 5083743 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Metric depth range: 1.7866381 → 20.037714\n",
      "\n",
      "0: 640x640 4 persons, 1 backpack, 2 chairs, 1 clock, 180.7ms\n",
      "Speed: 2.3ms preprocess, 180.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Estimated scale factor: 0.225\n",
      "Valid depth correspondences: 6674\n",
      "Scale:  0.22548272894776722\n",
      "62 !!! 255\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289729.564839 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289729.565953 5083786 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 6674\n",
      "Scale:  0.9999999683904086\n",
      "62 !!! 256\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289730.068220 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289730.069278 5083797 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 6674\n",
      "Scale:  1.0000000548712664\n",
      "62 !!! 257\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289730.690358 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289730.691456 5083810 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 6674\n",
      "Scale:  1.0000000548712664\n",
      "62 !!! 258\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n",
      "675600356462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289731.221133 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289731.222217 5083823 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Metric depth range: 1.8789985 → 19.982807\n",
      "\n",
      "0: 640x640 4 persons, 1 backpack, 1 chair, 165.5ms\n",
      "Speed: 2.5ms preprocess, 165.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Estimated scale factor: 0.230\n",
      "Valid depth correspondences: 6750\n",
      "Scale:  0.23018855970197516\n",
      "63 !!! 259\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289733.456054 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289733.457333 5083845 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 6750\n",
      "Scale:  0.999999993796737\n",
      "63 !!! 260\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289733.938234 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289733.939441 5083870 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 6750\n",
      "Scale:  0.999999993796737\n",
      "63 !!! 261\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289734.476597 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289734.477733 5083881 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 6750\n",
      "Scale:  0.999999993796737\n",
      "63 !!! 262\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n",
      "675700357037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289734.989887 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289734.991101 5083896 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Metric depth range: 1.6706086 → 20.166672\n",
      "\n",
      "0: 640x640 5 persons, 1 backpack, 1 chair, 162.9ms\n",
      "Speed: 2.4ms preprocess, 162.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Estimated scale factor: 0.229\n",
      "Valid depth correspondences: 6851\n",
      "Scale:  0.22856984768673114\n",
      "64 !!! 263\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289737.325003 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289737.326032 5083923 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 6851\n",
      "Scale:  0.9999999912057317\n",
      "64 !!! 264\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289737.814075 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289737.815402 5083939 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 6851\n",
      "Scale:  0.9999999912057317\n",
      "64 !!! 265\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289738.349455 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289738.350623 5083953 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 6851\n",
      "Scale:  0.9999999912057317\n",
      "64 !!! 266\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289738.828907 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289738.829934 5083964 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 6851\n",
      "Scale:  0.9999999912057317\n",
      "64 !!! 267\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n",
      "675800357675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289739.373150 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289739.374374 5083973 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Metric depth range: 3.4533205 → 19.985746\n",
      "\n",
      "0: 640x640 5 persons, 1 backpack, 1 chair, 1 clock, 192.0ms\n",
      "Speed: 2.2ms preprocess, 192.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Estimated scale factor: 0.231\n",
      "Valid depth correspondences: 6914\n",
      "Scale:  0.23132556441117788\n",
      "65 !!! 268\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289741.608887 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289741.610133 5084090 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 6914\n",
      "Scale:  0.999999969207709\n",
      "65 !!! 269\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289742.087655 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289742.088815 5084102 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 6914\n",
      "Scale:  1.0000000514662726\n",
      "65 !!! 270\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289742.629839 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289742.631057 5084159 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 6914\n",
      "Scale:  1.0000000514662726\n",
      "65 !!! 271\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289743.134203 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289743.135227 5084180 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 6914\n",
      "Scale:  1.0000000514662726\n",
      "65 !!! 272\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n",
      "675900358587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289743.665793 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289743.666909 5084195 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Metric depth range: 3.546848 → 19.98962\n",
      "\n",
      "0: 640x640 4 persons, 1 backpack, 1 chair, 215.1ms\n",
      "Speed: 3.4ms preprocess, 215.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Estimated scale factor: 0.236\n",
      "Valid depth correspondences: 6889\n",
      "Scale:  0.23625400910001934\n",
      "66 !!! 273\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289746.191499 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289746.193266 5084272 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 6889\n",
      "Scale:  1.000000023173431\n",
      "66 !!! 274\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289746.688327 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289746.689992 5084280 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 6889\n",
      "Scale:  1.000000023173431\n",
      "66 !!! 275\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289747.234209 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289747.235650 5084293 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 6889\n",
      "Scale:  1.000000023173431\n",
      "66 !!! 276\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n",
      "676000358750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289747.731718 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289747.732722 5084320 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Metric depth range: 3.507884 → 19.992956\n",
      "\n",
      "0: 640x640 4 persons, 1 chair, 1 clock, 197.4ms\n",
      "Speed: 4.3ms preprocess, 197.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Estimated scale factor: 0.237\n",
      "Valid depth correspondences: 6935\n",
      "Scale:  0.23739606738642482\n",
      "67 !!! 277\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289750.605160 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289750.606392 5084484 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 6935\n",
      "Scale:  1.000000066442491\n",
      "67 !!! 278\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289751.099819 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289751.101059 5084499 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 6935\n",
      "Scale:  0.9999999742760258\n",
      "67 !!! 279\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289751.634184 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289751.635326 5084530 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 6935\n",
      "Scale:  0.9999999742760258\n",
      "67 !!! 280\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n",
      "676100353087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289752.127092 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289752.128333 5084557 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Metric depth range: 3.2428393 → 19.988897\n",
      "\n",
      "0: 640x640 4 persons, 1 chair, 178.8ms\n",
      "Speed: 4.0ms preprocess, 178.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Estimated scale factor: 0.238\n",
      "Valid depth correspondences: 6987\n",
      "Scale:  0.23808526692349608\n",
      "68 !!! 281\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289754.802625 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289754.803643 5084664 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 6987\n",
      "Scale:  0.9999999416903897\n",
      "68 !!! 282\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289755.300041 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289755.301316 5084681 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 6987\n",
      "Scale:  1.0000000350339606\n",
      "68 !!! 283\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289755.834076 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289755.835195 5084709 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 6987\n",
      "Scale:  1.0000000350339606\n",
      "68 !!! 284\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "676200360500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289756.330483 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289756.331567 5084723 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Metric depth range: 3.075371 → 20.13222\n",
      "\n",
      "0: 640x640 4 persons, 1 chair, 1 clock, 177.8ms\n",
      "Speed: 3.4ms preprocess, 177.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Estimated scale factor: 0.243\n",
      "Valid depth correspondences: 7093\n",
      "Scale:  0.24274079020558736\n",
      "69 !!! 285\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289758.601890 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289758.603382 5084800 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 7093\n",
      "Scale:  0.9999999408057907\n",
      "69 !!! 286\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289759.083146 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289759.084547 5084808 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 7093\n",
      "Scale:  1.0000000349130782\n",
      "69 !!! 287\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289759.610758 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289759.612523 5084830 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 7093\n",
      "Scale:  1.0000000349130782\n",
      "69 !!! 288\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n",
      "676300357587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289760.101329 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289760.103292 5084870 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Metric depth range: 1.8110033 → 19.985113\n",
      "\n",
      "0: 640x640 3 persons, 1 potted plant, 1 clock, 190.5ms\n",
      "Speed: 2.7ms preprocess, 190.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Estimated scale factor: 0.242\n",
      "Valid depth correspondences: 7216\n",
      "Scale:  0.24243336006127397\n",
      "70 !!! 289\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289762.734104 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289762.735860 5084992 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 7216\n",
      "Scale:  1.0000000575624033\n",
      "70 !!! 290\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289763.214840 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289763.215981 5085019 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 7216\n",
      "Scale:  1.0000000575624033\n",
      "70 !!! 291\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289763.693351 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289763.694806 5085044 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "676400366050\n",
      "▶️ Metric depth range: 1.2569282 → 19.985025\n",
      "\n",
      "0: 640x640 2 persons, 1 clock, 189.7ms\n",
      "Speed: 4.0ms preprocess, 189.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Estimated scale factor: 0.240\n",
      "Valid depth correspondences: 7309\n",
      "Scale:  0.23980647406290184\n",
      "71 !!! 292\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289766.314294 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289766.315677 5085139 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 7309\n",
      "Scale:  0.9999999894266379\n",
      "71 !!! 293\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "676500366662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289766.794384 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289766.795517 5085160 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Metric depth range: 2.2973135 → 19.985247\n",
      "\n",
      "0: 640x640 2 persons, 1 potted plant, 1 clock, 164.7ms\n",
      "Speed: 3.3ms preprocess, 164.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Estimated scale factor: 0.235\n",
      "Valid depth correspondences: 7301\n",
      "Scale:  0.2349690678059434\n",
      "72 !!! 294\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289769.066935 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289769.068725 5085192 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated scale factor: 1.000\n",
      "Valid depth correspondences: 7301\n",
      "Scale:  1.000000030454046\n",
      "72 !!! 295\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289769.557060 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289769.559148 5085203 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "676600358212\n",
      "▶️ Metric depth range: 2.504492 → 19.981165\n",
      "\n",
      "0: 640x640 1 person, 1 potted plant, 1 remote, 1 clock, 165.5ms\n",
      "Speed: 2.7ms preprocess, 165.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Estimated scale factor: 0.233\n",
      "Valid depth correspondences: 7252\n",
      "Scale:  0.23347847174214548\n",
      "73 !!! 296\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289771.890078 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289771.891294 5085307 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "676700361375\n",
      "▶️ Metric depth range: 2.635856 → 19.986383\n",
      "\n",
      "0: 640x640 1 person, 1 potted plant, 1 remote, 1 clock, 190.7ms\n",
      "Speed: 2.5ms preprocess, 190.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Estimated scale factor: 0.231\n",
      "Valid depth correspondences: 7193\n",
      "Scale:  0.2312339234011131\n",
      "74 !!! 297\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289774.266627 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289774.268026 5085351 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "676800357837\n",
      "▶️ Metric depth range: 2.5102262 → 19.978722\n",
      "\n",
      "0: 640x640 1 chair, 1 potted plant, 1 remote, 1 clock, 166.2ms\n",
      "Speed: 2.2ms preprocess, 166.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "676900361000\n",
      "▶️ Metric depth range: 2.5030422 → 20.107292\n",
      "\n",
      "0: 640x640 1 chair, 2 potted plants, 1 remote, 1 clock, 197.6ms\n",
      "Speed: 2.8ms preprocess, 197.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "677000355300\n",
      "▶️ Metric depth range: 2.1398716 → 19.979582\n",
      "\n",
      "0: 640x640 2 chairs, 2 potted plants, 1 remote, 1 clock, 159.8ms\n",
      "Speed: 3.1ms preprocess, 159.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "677100363375\n",
      "▶️ Metric depth range: 1.882904 → 19.96508\n",
      "\n",
      "0: 640x640 2 potted plants, 1 remote, 180.2ms\n",
      "Speed: 2.8ms preprocess, 180.2ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "677200360050\n",
      "▶️ Metric depth range: 1.9401703 → 20.02227\n",
      "\n",
      "0: 640x640 1 potted plant, 1 remote, 180.2ms\n",
      "Speed: 2.1ms preprocess, 180.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "677300355500\n",
      "▶️ Metric depth range: 1.8388896 → 19.911343\n",
      "\n",
      "0: 640x640 1 potted plant, 1 remote, 182.6ms\n",
      "Speed: 3.4ms preprocess, 182.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "677400352175\n",
      "▶️ Metric depth range: 1.5681919 → 19.47994\n",
      "\n",
      "0: 640x640 1 person, 1 potted plant, 181.0ms\n",
      "Speed: 2.2ms preprocess, 181.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Estimated scale factor: 0.278\n",
      "Valid depth correspondences: 6164\n",
      "Scale:  0.27812946441347347\n",
      "81 !!! 298\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n",
      "677500355550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289788.725918 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289788.728093 5085598 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Metric depth range: 1.6370801 → 19.702896\n",
      "\n",
      "0: 640x640 1 person, 1 potted plant, 1 remote, 188.2ms\n",
      "Speed: 2.9ms preprocess, 188.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Estimated scale factor: 0.274\n",
      "Valid depth correspondences: 6104\n",
      "Scale:  0.27379831798347265\n",
      "82 !!! 299\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289791.016317 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289791.017401 5085630 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "677600361050\n",
      "▶️ Metric depth range: 1.6324242 → 20.004166\n",
      "\n",
      "0: 640x640 1 person, 1 potted plant, 1 remote, 165.1ms\n",
      "Speed: 2.3ms preprocess, 165.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Estimated scale factor: 0.282\n",
      "Valid depth correspondences: 6104\n",
      "Scale:  0.2815296057294623\n",
      "83 !!! 300\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289793.340564 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289793.341856 5085683 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "677700361625\n",
      "▶️ Metric depth range: 1.6890194 → 20.17469\n",
      "\n",
      "0: 640x640 1 person, 1 potted plant, 1 remote, 1 cell phone, 188.4ms\n",
      "Speed: 2.4ms preprocess, 188.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Estimated scale factor: 0.277\n",
      "Valid depth correspondences: 6198\n",
      "Scale:  0.2771283953820399\n",
      "84 !!! 301\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289795.724191 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289795.725545 5085740 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "677800356250\n",
      "▶️ Metric depth range: 1.7497698 → 19.993765\n",
      "\n",
      "0: 640x640 1 person, 1 potted plant, 1 remote, 1 cell phone, 178.6ms\n",
      "Speed: 3.5ms preprocess, 178.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Estimated scale factor: 0.276\n",
      "Valid depth correspondences: 6213\n",
      "Scale:  0.27642690658652863\n",
      "85 !!! 302\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289798.259983 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289798.261176 5085781 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "677900360587\n",
      "▶️ Metric depth range: 1.7063859 → 20.179258\n",
      "\n",
      "0: 640x640 1 person, 1 potted plant, 1 remote, 1 cell phone, 163.3ms\n",
      "Speed: 2.4ms preprocess, 163.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Estimated scale factor: 0.279\n",
      "Valid depth correspondences: 6152\n",
      "Scale:  0.2789900199686873\n",
      "86 !!! 303\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289800.726882 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289800.728189 5085803 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "678000356300\n",
      "▶️ Metric depth range: 1.6123929 → 18.522413\n",
      "\n",
      "0: 640x640 1 person, 1 potted plant, 1 remote, 1 cell phone, 170.9ms\n",
      "Speed: 3.4ms preprocess, 170.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Estimated scale factor: 0.297\n",
      "Valid depth correspondences: 6084\n",
      "Scale:  0.2966162490286728\n",
      "87 !!! 304\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289803.078215 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289803.080167 5085848 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "678100356925\n",
      "▶️ Metric depth range: 1.6263905 → 19.44639\n",
      "\n",
      "0: 640x640 1 person, 1 potted plant, 1 remote, 1 cell phone, 173.8ms\n",
      "Speed: 2.4ms preprocess, 173.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Estimated scale factor: 0.306\n",
      "Valid depth correspondences: 6002\n",
      "Scale:  0.30608433875876173\n",
      "88 !!! 305\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289805.504781 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289805.506416 5085893 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "678200357500\n",
      "▶️ Metric depth range: 1.6881179 → 18.629803\n",
      "\n",
      "0: 640x640 1 person, 1 potted plant, 1 remote, 1 cell phone, 186.0ms\n",
      "Speed: 2.2ms preprocess, 186.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Estimated scale factor: 0.320\n",
      "Valid depth correspondences: 5942\n",
      "Scale:  0.32007306833460913\n",
      "89 !!! 306\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289807.876074 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289807.877723 5085930 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "678300358087\n",
      "▶️ Metric depth range: 1.869811 → 17.19278\n",
      "\n",
      "0: 640x640 1 person, 1 potted plant, 1 remote, 1 cell phone, 169.3ms\n",
      "Speed: 3.5ms preprocess, 169.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Estimated scale factor: 0.346\n",
      "Valid depth correspondences: 5941\n",
      "Scale:  0.3463065732572439\n",
      "90 !!! 307\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289810.355957 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289810.357124 5086011 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "678400354962\n",
      "▶️ Metric depth range: 1.902261 → 17.588839\n",
      "\n",
      "0: 640x640 1 person, 1 potted plant, 171.2ms\n",
      "Speed: 3.3ms preprocess, 171.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Estimated scale factor: 0.351\n",
      "Valid depth correspondences: 5955\n",
      "Scale:  0.3510710341352844\n",
      "91 !!! 308\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n",
      "678500355587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289812.935156 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289812.936394 5086101 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Metric depth range: 1.8718172 → 17.704155\n",
      "\n",
      "0: 640x640 1 person, 1 potted plant, 1 cell phone, 179.1ms\n",
      "Speed: 2.3ms preprocess, 179.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Estimated scale factor: 0.355\n",
      "Valid depth correspondences: 5887\n",
      "Scale:  0.3548811077604494\n",
      "92 !!! 309\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289815.106519 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289815.107574 5086136 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "678600359925\n",
      "▶️ Metric depth range: 1.856062 → 18.37455\n",
      "\n",
      "0: 640x640 1 person, 1 cell phone, 158.8ms\n",
      "Speed: 2.1ms preprocess, 158.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Estimated scale factor: 0.346\n",
      "Valid depth correspondences: 5764\n",
      "Scale:  0.34606824063130226\n",
      "93 !!! 310\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n",
      "678700356800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289817.499501 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289817.500672 5086188 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Metric depth range: 1.6978447 → 16.789373\n",
      "\n",
      "0: 640x640 1 person, 1 cell phone, 168.1ms\n",
      "Speed: 2.8ms preprocess, 168.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Estimated scale factor: 0.363\n",
      "Valid depth correspondences: 5661\n",
      "Scale:  0.3629697224813242\n",
      "94 !!! 311\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n",
      "678800357375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289819.697743 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289819.698952 5086217 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Metric depth range: 1.8448952 → 16.254635\n",
      "\n",
      "0: 640x640 1 person, 1 remote, 1 cell phone, 186.2ms\n",
      "Speed: 3.1ms preprocess, 186.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Estimated scale factor: 0.350\n",
      "Valid depth correspondences: 5557\n",
      "Scale:  0.34963204298888356\n",
      "95 !!! 312\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289822.075509 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289822.076716 5086251 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "678900357962\n",
      "▶️ Metric depth range: 1.6830114 → 17.291765\n",
      "\n",
      "0: 640x640 1 person, 1 remote, 1 cell phone, 179.8ms\n",
      "Speed: 2.4ms preprocess, 179.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Estimated scale factor: 0.338\n",
      "Valid depth correspondences: 5452\n",
      "Scale:  0.3377956131001534\n",
      "96 !!! 313\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289824.437411 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289824.438703 5086272 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "679000354425\n",
      "▶️ Metric depth range: 1.5953486 → 17.909496\n",
      "\n",
      "0: 640x640 1 person, 1 remote, 1 cell phone, 165.9ms\n",
      "Speed: 2.5ms preprocess, 165.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Estimated scale factor: 0.345\n",
      "Valid depth correspondences: 5414\n",
      "Scale:  0.34498343556734534\n",
      "97 !!! 314\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289826.770771 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289826.772062 5086381 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "679100359175\n",
      "▶️ Metric depth range: 1.6370044 → 18.937569\n",
      "\n",
      "0: 640x640 1 person, 1 remote, 1 cell phone, 181.2ms\n",
      "Speed: 2.8ms preprocess, 181.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Estimated scale factor: 0.337\n",
      "Valid depth correspondences: 5281\n",
      "Scale:  0.3367319279897734\n",
      "98 !!! 315\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289829.120766 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289829.121788 5086435 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "679200357212\n",
      "▶️ Metric depth range: 1.7003176 → 16.859194\n",
      "\n",
      "0: 640x640 1 person, 1 cell phone, 170.0ms\n",
      "Speed: 2.4ms preprocess, 170.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Estimated scale factor: 0.354\n",
      "Valid depth correspondences: 5100\n",
      "Scale:  0.35357781994452686\n",
      "99 !!! 316\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n",
      "679300358462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289831.487908 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289831.489402 5086473 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Metric depth range: 1.5757229 → 16.860281\n",
      "\n",
      "0: 640x640 1 person, 1 remote, 1 cell phone, 183.8ms\n",
      "Speed: 2.5ms preprocess, 183.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Estimated scale factor: 0.365\n",
      "Valid depth correspondences: 4912\n",
      "Scale:  0.36503474846742834\n",
      "100 !!! 317\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289833.756933 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289833.758166 5086501 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "679400359050\n",
      "▶️ Metric depth range: 1.4343703 → 15.390223\n",
      "\n",
      "0: 640x640 1 person, 172.4ms\n",
      "Speed: 3.4ms preprocess, 172.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Estimated scale factor: 0.411\n",
      "Valid depth correspondences: 4681\n",
      "Scale:  0.4110055535435907\n",
      "101 !!! 318\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n",
      "679500359675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289836.090168 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289836.091370 5086540 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Metric depth range: 1.5574884 → 14.0532465\n",
      "\n",
      "0: 640x640 1 person, 1 cell phone, 183.4ms\n",
      "Speed: 2.3ms preprocess, 183.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Estimated scale factor: 0.428\n",
      "Valid depth correspondences: 4476\n",
      "Scale:  0.42798509205304913\n",
      "102 !!! 319\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n",
      "679600357300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289838.376384 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289838.377783 5086575 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Metric depth range: 1.6962333 → 15.068285\n",
      "\n",
      "0: 640x640 1 person, 1 cell phone, 172.0ms\n",
      "Speed: 2.6ms preprocess, 172.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Estimated scale factor: 0.437\n",
      "Valid depth correspondences: 4322\n",
      "Scale:  0.43685058642337093\n",
      "103 !!! 320\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n",
      "679700361000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289840.590067 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289840.591196 5086613 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Metric depth range: 1.6822053 → 14.806318\n",
      "\n",
      "0: 640x640 1 person, 1 cell phone, 170.8ms\n",
      "Speed: 3.1ms preprocess, 170.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Estimated scale factor: 0.467\n",
      "Valid depth correspondences: 4147\n",
      "Scale:  0.46663305481466066\n",
      "104 !!! 321\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n",
      "679800364212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289842.870958 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289842.872147 5086648 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Metric depth range: 1.6051416 → 14.956678\n",
      "\n",
      "0: 640x640 1 person, 1 cell phone, 169.4ms\n",
      "Speed: 3.2ms preprocess, 169.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Estimated scale factor: 0.475\n",
      "Valid depth correspondences: 3956\n",
      "Scale:  0.47450949038564055\n",
      "105 !!! 322\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n",
      "679900355587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289845.068589 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289845.070607 5086682 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Metric depth range: 1.6001166 → 15.312283\n",
      "\n",
      "0: 640x640 1 person, 1 cell phone, 170.1ms\n",
      "Speed: 2.2ms preprocess, 170.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Estimated scale factor: 0.468\n",
      "Valid depth correspondences: 3736\n",
      "Scale:  0.4680543913404732\n",
      "106 !!! 323\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n",
      "680000359500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289847.328784 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289847.329956 5086707 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Metric depth range: 1.6271014 → 15.9764385\n",
      "\n",
      "0: 640x640 1 person, 1 cell phone, 167.6ms\n",
      "Speed: 3.1ms preprocess, 167.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Estimated scale factor: 0.499\n",
      "Valid depth correspondences: 3541\n",
      "Scale:  0.4994174299941886\n",
      "107 !!! 324\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n",
      "680100362625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289849.529983 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289849.531149 5086736 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Metric depth range: 1.3235894 → 14.530821\n",
      "\n",
      "0: 640x640 1 person, 1 cell phone, 170.6ms\n",
      "Speed: 2.6ms preprocess, 170.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Estimated scale factor: 0.588\n",
      "Valid depth correspondences: 3375\n",
      "Scale:  0.5884424754342238\n",
      "108 !!! 325\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "680200365175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289851.769668 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289851.770926 5086776 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Metric depth range: 1.4214363 → 13.0470085\n",
      "\n",
      "0: 640x640 1 person, 1 cell phone, 178.2ms\n",
      "Speed: 2.2ms preprocess, 178.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Estimated scale factor: 0.616\n",
      "Valid depth correspondences: 3251\n",
      "Scale:  0.6164763243760423\n",
      "109 !!! 326\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n",
      "680300361425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289853.943904 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289853.945159 5086836 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Metric depth range: 1.2818633 → 12.306962\n",
      "\n",
      "0: 640x640 1 person, 1 cell phone, 162.6ms\n",
      "Speed: 2.7ms preprocess, 162.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Estimated scale factor: 0.655\n",
      "Valid depth correspondences: 3140\n",
      "Scale:  0.6550458317507591\n",
      "110 !!! 327\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n",
      "680400361462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289856.198299 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289856.199357 5086866 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Metric depth range: 1.6195697 → 12.223676\n",
      "\n",
      "0: 640x640 1 person, 1 cell phone, 183.6ms\n",
      "Speed: 2.7ms preprocess, 183.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Estimated scale factor: 0.603\n",
      "Valid depth correspondences: 3023\n",
      "Scale:  0.6033380462747984\n",
      "111 !!! 328\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n",
      "680500351625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289858.459497 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289858.460692 5086919 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Metric depth range: 1.525147 → 12.583738\n",
      "\n",
      "0: 640x640 1 person, 1 cell phone, 165.3ms\n",
      "Speed: 2.2ms preprocess, 165.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Estimated scale factor: 0.387\n",
      "Valid depth correspondences: 2915\n",
      "Scale:  0.38713599633591567\n",
      "112 !!! 329\n",
      "Results: <class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "no faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753289860.659082 5076740 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2 Pro\n",
      "W0000 00:00:1753289860.661076 5086942 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    }
   ],
   "source": [
    "# Apply Tracking, Depth, FaceBlur and Visualize the frames\n",
    "\n",
    "import os\n",
    "\n",
    "output_dir = os.path.join(base_dir, \"Generated_Diagrams&Frames\", video_name, \"video_frames\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "W, H = 1408, 1408\n",
    "focal = 450 * 1.48 \n",
    "dst_calib = get_linear_camera_calibration(W, H, focal, \"camera-rgb\")\n",
    "fx = fy = focal                       \n",
    "cx = W / 2\n",
    "cy = H / 2\n",
    "\n",
    "focal_length   = [fx, fy]          \n",
    "principal_point = [cy, cx]  \n",
    "timestamps = vrs_data_provider.get_timestamps_ns(rgb_stream_id, TimeDomain.DEVICE_TIME)\n",
    "\n",
    "glasses_xyz_positions = []\n",
    "opponent_xyz_positions = []\n",
    "pedestrians_xyz_positions = []\n",
    "\n",
    "csv_path = os.path.join(base_dir, \"Generated_Diagrams&Frames\", video_name, \"trajectory_data.csv\")\n",
    "if os.path.exists(csv_path):\n",
    "    os.remove(csv_path)\n",
    "init_trajectory_csv(csv_path)\n",
    "\n",
    "count_shift = 0\n",
    "sum_shift = 0.0\n",
    "\n",
    "frame_index = -1\n",
    "\n",
    "T_world_device = []\n",
    "\n",
    "for timestamp in timestamps: # Selecting a portion of the frames in the video based on timestamp, [40:110] for Nima's Video in INM\n",
    "    nearest_pose_info = get_nearest_pose(closed_loop_trajectory, timestamp)\n",
    "    print(timestamp)\n",
    "    if nearest_pose_info:\n",
    "        T_world_device = nearest_pose_info.transform_world_device\n",
    "    if T_world_device == []:\n",
    "        continue\n",
    "\n",
    "    frame_index += 1\n",
    "    \n",
    "    # Calculate Glasses XYZ\n",
    "    translation = T_world_device.translation()      \n",
    "    tx = translation[0][0]  \n",
    "    ty = translation[0][1]  \n",
    "    tz = translation[0][2]\n",
    "    tt = [tx, ty, tz]   # Translation vector: position of glasses in world coordinates\n",
    "    \n",
    "    q_wxyz = rotation.to_quat().flatten() # Aria provides [w, x, y, z]\n",
    "    q_xyzw = [q_wxyz[1], q_wxyz[2], q_wxyz[3], q_wxyz[0]]  # [x, y, z, w]\n",
    "    RR = R_scipy.from_quat(q_xyzw).as_matrix()\n",
    "    glasses_xyz_positions.append(tt)\n",
    "    \n",
    "    image_data, _ = vrs_data_provider.get_image_data_by_time_ns(\n",
    "        rgb_stream_id, timestamp, TimeDomain.DEVICE_TIME, TimeQueryOptions.BEFORE\n",
    "    )\n",
    "    if image_data:\n",
    "        img = image_data.to_numpy_array()  # Convert to NumPy array\n",
    "        img_bgr = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)  # Convert to OpenCV format\n",
    "\n",
    "        # Apply the undistortion correction\n",
    "        undistorted_rgb_image = distort_by_calibration(\n",
    "            img_bgr, dst_calib, rgb_camera_calibration\n",
    "        )\n",
    "\n",
    "        frame = undistorted_rgb_image\n",
    "        frame = cv2.rotate(frame, cv2.ROTATE_90_CLOCKWISE)\n",
    "\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  # Convert BGR (OpenCV) to RGB\n",
    "        pil_frame = Image.fromarray(frame_rgb)  \n",
    "        orig_w, orig_h = pil_frame.size\n",
    "            \n",
    "        depthResult = pipe(pil_frame)\n",
    "        depthModel     = pipe.model\n",
    "        processor = pipe.image_processor\n",
    "        \n",
    "        inputs = processor(images=pil_frame, return_tensors=\"pt\").to(depthModel.device)\n",
    "        with torch.no_grad():\n",
    "            outputs = depthModel(**inputs)\n",
    "            pred_depth = outputs.predicted_depth  \n",
    "        \n",
    "        small = pred_depth.squeeze(0).squeeze(0).cpu().numpy()  # shape: (h', w')\n",
    "        depth_map = cv2.resize(small, (orig_w, orig_h), interpolation=cv2.INTER_CUBIC)\n",
    "        \n",
    "        depth_np = np.array(depth_map, dtype=np.float32) \n",
    "\n",
    "        print(\"▶️ Metric depth range:\", depth_map.min(), \"→\", depth_map.max())\n",
    "\n",
    "        results = model.track(\n",
    "            source=frame, \n",
    "            persist=True, \n",
    "            tracker='/Users/behnood/miniforge3/lib/python3.10/site-packages/ultralytics/cfg/trackers/bytetrack.yaml'\n",
    "        )\n",
    "                \n",
    "        boxes = results[0].boxes.xyxy.cpu().numpy().astype(int)  \n",
    "        class_ids = results[0].boxes.cls  \n",
    "        confidences = results[0].boxes.conf.cpu().numpy() \n",
    "        if results[0].boxes.id is not None:\n",
    "            ids = results[0].boxes.id.cpu().numpy().astype(int)  # Get bounding box coordinates (x1, y1, x2, y2)\n",
    "        else:\n",
    "            ids = [404] * len(boxes)\n",
    "\n",
    "        depth_np_normalized = (depth_np - depth_np.min()) / (depth_np.max() - depth_np.min())\n",
    "        inv_depth_np_normalized = 1.0 - depth_np_normalized  # Invert the normalized values\n",
    "        depth_colormap = cv2.applyColorMap((inv_depth_np_normalized * 255).astype(np.uint8), cv2.COLORMAP_INFERNO)\n",
    "        # frame = depth_colormap\n",
    "        \n",
    "        current_id = 0\n",
    "        pedestrians_in_frame = {}\n",
    "        for box, id, class_id, confidence in zip(boxes, ids, class_ids, confidences):\n",
    "            if class_id != 0:\n",
    "                frame_filename = os.path.join(output_dir, f\"frame_{frame_index:04d}.png\")\n",
    "                cv2.imwrite(frame_filename, frame)\n",
    "                # print(frame_index, \"@@@\", len(opponent_xyz_positions))\n",
    "                # cv2.imshow(\"Slam\", frame)\n",
    "                continue # Filter only the human objects\n",
    "            # print(\"Person \", id, \", confidence: \", confidence)\n",
    "\n",
    "            # object_3d_world_point = compute_3d_world_point(box, depth_map, principal_point, focal_length, RR, tt)\n",
    "\n",
    "            current_id += 1\n",
    "            \n",
    "            if current_id > 7:\n",
    "                continue # This line should be removed\n",
    "\n",
    "\n",
    "            # NNNNEEEEWWWWW NEW\n",
    "            scaled_depth_map, scale_val = improve_depth_scale(depth_map, principal_point, focal_length, RR, tt)\n",
    "            print(\"Scale: \", scale_val)\n",
    "            depth_map = scaled_depth_map\n",
    "\n",
    "            \n",
    "            object_3d_world_point = compute_3d_world_point(box, depth_map, principal_point, focal_length, RR, tt)\n",
    "\n",
    "            opponent_xyz_positions.append(object_3d_world_point)\n",
    "            \n",
    "            print(frame_index, \"!!!\", len(opponent_xyz_positions))\n",
    "\n",
    "            # write_trajectory_row(\n",
    "            #     csv_path, frame_index, tt, object_3d_world_point, box,\n",
    "            #     depth_map, principal_point, focal_length, RR, q_wxyz, 0\n",
    "            # )\n",
    "\n",
    "            # Draw bounding box normally (before rotation)\n",
    "                \n",
    "            cv2.rectangle(frame, (box[0], box[1]), (box[2], box[3]), (0, 255, 255), 2)\n",
    "\n",
    "            # Apply FaceBlur\n",
    "            blur_faces_in_box_mediapipe(frame, box)\n",
    "\n",
    "            center_x = (box[0] + box[2]) // 2\n",
    "            center_y = (box[1] + box[3]) // 2\n",
    "\n",
    "            depth_value = float(depth_map[center_y, center_x])\n",
    "            depth_value = round(depth_value, 2)            \n",
    "\n",
    "            pedestrians_in_frame[int(id)] = {\n",
    "                \"xyz\": object_3d_world_point,\n",
    "                \"depth\": depth_value\n",
    "            }\n",
    "            # print(f\"bbox: {box}\\n\")\n",
    "            \n",
    "            # Draw label in rotated-aware position\n",
    "            # label = f\"depth: {depth_value}\"\n",
    "            label = f\"id: {id}, depth: {depth_value}m\"\n",
    "            (label_width, label_height), baseline = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)\n",
    "            \n",
    "            # Instead of box[1] - h (Y-axis), move on X-axis because of rotation\n",
    "            label_x = box[1] - label_height - 5\n",
    "            label_y = box[0]\n",
    "            \n",
    "            # Draw background rectangle for the label\n",
    "            cv2.rectangle(\n",
    "                frame,\n",
    "                (label_y, label_x),  # note swapped coords\n",
    "                (label_y + label_width, label_x + label_height + baseline),\n",
    "                (0, 255, 255),\n",
    "                thickness=cv2.FILLED\n",
    "            )\n",
    "            \n",
    "            # Draw label text\n",
    "            cv2.putText(\n",
    "                frame,\n",
    "                label,\n",
    "                (label_y, label_x + label_height),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                0.5,\n",
    "                (0, 0, 0),\n",
    "                thickness=1\n",
    "            )\n",
    "\n",
    "            # Show the frame\n",
    "            frame_filename = os.path.join(output_dir, f\"frame_{frame_index:04d}.png\")\n",
    "            cv2.imwrite(frame_filename, frame)\n",
    "\n",
    "        if len(opponent_xyz_positions) <= frame_index:\n",
    "            if len(boxes) == 0:\n",
    "                frame_filename = os.path.join(output_dir, f\"frame_{frame_index:04d}.png\")\n",
    "                cv2.imwrite(frame_filename, frame)   \n",
    "            if len(opponent_xyz_positions) > 0:\n",
    "                opponent_xyz_positions.append(opponent_xyz_positions[-1])\n",
    "            else:\n",
    "                opponent_xyz_positions.append([0, 0, 0])\n",
    "\n",
    "        pedestrians_xyz_positions.append(pedestrians_in_frame)\n",
    "        write_trajectory_row(\n",
    "                csv_path, frame_index, tt, object_3d_world_point, box,\n",
    "                depth_map, principal_point, focal_length, RR, q_wxyz, pedestrians_in_frame\n",
    "            )\n",
    "            # cv2.imshow(\"Slam\", frame)\n",
    "\n",
    "#             if cv2.waitKey(8) & 0xFF == ord('q'):\n",
    "#                 break\n",
    "\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9767941e-7159-41f5-b6b1-551114757a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import defaultdict\n",
    "\n",
    "# frame_counts = defaultdict(list)  # id -> list of frame indices\n",
    "\n",
    "# # Build frame appearance index\n",
    "# for frame_idx, id_dict in enumerate(pedestrians_xyz_positions):\n",
    "#     for pid in id_dict:\n",
    "#         frame_counts[pid].append(frame_idx)\n",
    "\n",
    "# # Compute stable streaks\n",
    "# def longest_consecutive_streak(frames):\n",
    "#     streak = max_streak = 1\n",
    "#     for i in range(1, len(frames)):\n",
    "#         if frames[i] == frames[i - 1] + 1:\n",
    "#             streak += 1\n",
    "#             max_streak = max(max_streak, streak)\n",
    "#         else:\n",
    "#             streak = 1\n",
    "#     return max_streak\n",
    "\n",
    "# qualified_ids = []\n",
    "# for pid, frames in frame_counts.items():\n",
    "#     if len(frames) >= 15 and longest_consecutive_streak(frames) >= 15:\n",
    "#         qualified_ids.append((pid, len(frames)))\n",
    "\n",
    "# # Sort by appearance count, keep top 3\n",
    "# qualified_ids.sort(key=lambda x: -x[1])\n",
    "# top3_ids = [pid for pid, _ in qualified_ids[:3]]\n",
    "# print(\"Top 3 stable IDs:\", top3_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3d2b870a-d2cd-4cd9-8a59-1d6c4d241e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Selected top IDs for tracking: [2, 13, 12]\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# 1. Track frame appearances and depth coverage\n",
    "frame_counts = defaultdict(list)            # id -> list of frame indices\n",
    "depth_history = defaultdict(list)           # id -> list of depths\n",
    "\n",
    "for frame_idx, id_dict in enumerate(pedestrians_xyz_positions):\n",
    "    for pid, data in id_dict.items():\n",
    "        frame_counts[pid].append(frame_idx)\n",
    "        depth_history[pid].append(data[\"depth\"])\n",
    "\n",
    "# 2. Define utility for longest consecutive appearance streak\n",
    "def longest_consecutive_streak(frames):\n",
    "    if not frames:\n",
    "        return 0\n",
    "    frames.sort()\n",
    "    streak = max_streak = 1\n",
    "    for i in range(1, len(frames)):\n",
    "        if frames[i] == frames[i - 1] + 1:\n",
    "            streak += 1\n",
    "            max_streak = max(max_streak, streak)\n",
    "        else:\n",
    "            streak = 1\n",
    "    return max_streak\n",
    "\n",
    "# 3. Filter candidates based on constraints\n",
    "qualified_ids = []\n",
    "for pid in frame_counts:\n",
    "    appearances = frame_counts[pid]\n",
    "    depths = depth_history[pid]\n",
    "\n",
    "    if longest_consecutive_streak(appearances) >= 15 and any(d >= 2.0 for d in depths):\n",
    "        qualified_ids.append((pid, len(appearances)))  # include total count for sorting\n",
    "\n",
    "# 4. Sort by most frequent appearances\n",
    "qualified_ids.sort(key=lambda x: -x[1])\n",
    "\n",
    "# 5. Pick top 3 (or fewer if needed, but at least 1)\n",
    "top_ids = [pid for pid, _ in qualified_ids[:3]]\n",
    "if len(top_ids) == 0:\n",
    "    # fallback: pick the best single ID based on raw appearance\n",
    "    fallback = max(frame_counts.items(), key=lambda x: len(x[1]))[0]\n",
    "    top_ids = [fallback]\n",
    "\n",
    "print(\"✅ Selected top IDs for tracking:\", top_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b6feb378-06ef-4998-9ff4-980a88d4a383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Initialize an empty list of length = total frames\n",
    "num_frames = len(pedestrians_xyz_positions)\n",
    "filtered_positions = [{} for _ in range(num_frames)]\n",
    "\n",
    "# Step 2: Extract and complete each ID's timeline\n",
    "for pid in top_ids:\n",
    "    # Get frames where the ID is present\n",
    "    pid_frames = [i for i, frame_data in enumerate(pedestrians_xyz_positions) if pid in frame_data]\n",
    "    if not pid_frames:\n",
    "        continue\n",
    "\n",
    "    first_frame = pid_frames[0]\n",
    "    last_frame = pid_frames[-1]\n",
    "\n",
    "    # Get the first and last known values\n",
    "    first_value = pedestrians_xyz_positions[first_frame][pid]\n",
    "    last_value = pedestrians_xyz_positions[last_frame][pid]\n",
    "\n",
    "    prev_value = None\n",
    "\n",
    "    for i in range(num_frames):\n",
    "        if pid in pedestrians_xyz_positions[i]:\n",
    "            # Use actual data\n",
    "            current_value = pedestrians_xyz_positions[i][pid]\n",
    "            prev_value = current_value\n",
    "        else:\n",
    "            # Padding logic\n",
    "            if i < first_frame:\n",
    "                current_value = first_value  # Before first appearance\n",
    "            elif i > last_frame:\n",
    "                current_value = last_value  # After last appearance\n",
    "            elif prev_value is not None:\n",
    "                current_value = prev_value  # In-between gaps\n",
    "            else:\n",
    "                continue  # shouldn't happen, but safe fallback\n",
    "\n",
    "        # Update filtered list\n",
    "        filtered_positions[i][pid] = current_value\n",
    "\n",
    "# print(filtered_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c76049-20d0-4300-94b1-d7430a5dc8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered_positions = []\n",
    "# for frame_data in pedestrians_xyz_positions:\n",
    "#     filtered = {pid: frame_data[pid] for pid in top_ids if pid in frame_data}\n",
    "#     filtered_positions.append(filtered)\n",
    "\n",
    "# # print(filtered_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad68351-493c-481a-8ecd-cfdc357ac70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function for Visualizing the xyz positions of the glasses and the pedestrian in 2D\n",
    "\n",
    "# from IPython.display import HTML\n",
    "# import matplotlib.animation as animation\n",
    "\n",
    "# def visualize_two_3d_xyz(xyz_positions1, xyz_positions2):\n",
    "#     xyz_positions1 = np.array(xyz_positions1)\n",
    "#     xyz_positions2 = np.array(xyz_positions2)\n",
    "\n",
    "#     fig, ax = plt.subplots()\n",
    "\n",
    "#     # Extract coordinates\n",
    "#     x1, y1 = xyz_positions1[:, 0], xyz_positions1[:, 1]\n",
    "#     x2, y2 = xyz_positions2[:, 0], xyz_positions2[:, 1]\n",
    "\n",
    "#     # Combine for axis scaling\n",
    "#     all_x = np.concatenate((x1, x2))\n",
    "#     all_y = np.concatenate((y1, y2))\n",
    "    \n",
    "#     x_min, x_max = np.min(all_x), np.max(all_x)\n",
    "#     y_min, y_max = np.min(all_y), np.max(all_y)\n",
    "\n",
    "#     scale_factor = 0.5\n",
    "#     x_range = x_max - x_min\n",
    "#     y_range = y_max - y_min\n",
    "#     max_range = max(x_range, y_range)\n",
    "#     x_center = (x_max + x_min) / 2\n",
    "#     y_center = (y_max + y_min) / 2\n",
    "\n",
    "#     ax.set_xlim(x_center - max_range / 2 - scale_factor, x_center + max_range / 2 + scale_factor)\n",
    "#     ax.set_ylim(y_center - max_range / 2 - scale_factor, y_center + max_range / 2 + scale_factor)\n",
    "#     ax.set_aspect('equal')\n",
    "\n",
    "#     ax.set_xlabel(\"X Position (m)\")\n",
    "#     ax.set_ylabel(\"Y Position (m)\")\n",
    "\n",
    "#     # Two scatter plots for two sets of data\n",
    "#     sc1 = ax.scatter([], [], c='red', label='Person 1')\n",
    "#     sc2 = ax.scatter([], [], c='blue', label='Person 2')\n",
    "\n",
    "#     ax.legend()\n",
    "\n",
    "#     num_frames = 100\n",
    "#     interval = 20000 / num_frames\n",
    "\n",
    "#     def update(frame):\n",
    "#         n1 = int((frame / num_frames) * len(x1))\n",
    "#         n2 = int((frame / num_frames) * len(x2))\n",
    "\n",
    "#         sc1.set_offsets(np.c_[x1[:n1], y1[:n1]])\n",
    "#         sc2.set_offsets(np.c_[x2[:n2], y2[:n2]])\n",
    "#         return sc1, sc2\n",
    "\n",
    "#     ani = animation.FuncAnimation(fig, update, frames=num_frames, interval=interval, blit=False)\n",
    "#     plt.close(fig)\n",
    "#     return HTML(ani.to_jshtml())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4154734b-2f99-47b5-95ae-b6eed7d75d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for smoothing trajectories with Kalman Filter (x and y are affected)\n",
    "\n",
    "def smooth_xy_coordinates_with_kalman(data_xyz):\n",
    "    \"\"\"\n",
    "    Apply Kalman filter to smooth x and y coordinates from 3D trajectory data.\n",
    "    \n",
    "    Parameters:\n",
    "    data_xyz (list of [x, y, z]): Input list of 3D points.\n",
    "\n",
    "    Returns:\n",
    "    list of [x, y, z]: Smoothed 3D points, with x and y filtered using Kalman Filter.\n",
    "    \"\"\"\n",
    "    data_xyz = np.array(data_xyz)\n",
    "    observed_states = data_xyz[:, :2]  # Only x and y\n",
    "\n",
    "    if len(observed_states) < 2:\n",
    "        return data_xyz.tolist()\n",
    "\n",
    "    # Kalman Filter setup\n",
    "    transition_matrix = [[1, 1, 0, 0],\n",
    "                         [0, 1, 0, 0],\n",
    "                         [0, 0, 1, 1],\n",
    "                         [0, 0, 0, 1]]\n",
    "    \n",
    "    observation_matrix = [[1, 0, 0, 0],\n",
    "                          [0, 0, 1, 0]]\n",
    "    \n",
    "    initial_state_mean = [observed_states[0][0], 0, observed_states[0][1], 0]\n",
    "\n",
    "    kf = KalmanFilter(\n",
    "        transition_matrices=transition_matrix,\n",
    "        observation_matrices=observation_matrix,\n",
    "        transition_covariance=1e-5 * np.eye(4),\n",
    "        observation_covariance=0.05**2 * np.eye(2),\n",
    "        initial_state_mean=initial_state_mean\n",
    "    )\n",
    "\n",
    "    kf = kf.em(observed_states, n_iter=10)\n",
    "    smoothed_states, _ = kf.smooth(observed_states)\n",
    "\n",
    "    # Replace x and y with smoothed values, keep z the same\n",
    "    smoothed_data = []\n",
    "    for i, original in enumerate(data_xyz):\n",
    "        smoothed_data.append([smoothed_states[i][0], smoothed_states[i][2], original[2]])\n",
    "\n",
    "    return smoothed_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f602963-730d-4bd3-9301-b6e3b64f8b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step 1: Apply Kalman smoothing for each ID\n",
    "# for pid in top_ids:\n",
    "#     # Extract the xyz trajectory\n",
    "#     trajectory_xyz = []\n",
    "#     for frame in filtered_positions:\n",
    "#         if pid in frame:\n",
    "#             trajectory_xyz.append(frame[pid][\"xyz\"])\n",
    "#         else:\n",
    "#             trajectory_xyz.append(None)\n",
    "\n",
    "#     # Fill in None values with the last known position to match what Kalman needs\n",
    "#     filled_xyz = []\n",
    "#     last_valid = trajectory_xyz[0]\n",
    "#     for pt in trajectory_xyz:\n",
    "#         if pt is None:\n",
    "#             filled_xyz.append(last_valid)\n",
    "#         else:\n",
    "#             filled_xyz.append(pt)\n",
    "#             last_valid = pt\n",
    "\n",
    "#     # Apply Kalman smoothing\n",
    "#     smoothed_xyz = smooth_xy_coordinates_with_kalman(filled_xyz)\n",
    "\n",
    "#     # Update the filtered_positions with smoothed values\n",
    "#     for i, frame in enumerate(filtered_positions):\n",
    "#         if pid in frame:\n",
    "#             frame[pid][\"xyz\"] = smoothed_xyz[i]\n",
    "\n",
    "# print(filtered_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a11068-43a8-49ef-bf6a-dfb766d04e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Smoothen and Visualize the trajectories of the glasses and the pedestrian\n",
    "\n",
    "# # ONLY LINE THAT MATTERS\n",
    "# smoothed_opponent_xyz_positions = smooth_xy_coordinates_with_kalman(opponent_xyz_positions)\n",
    "# ## FOR TEST AND DEBUG\n",
    "# # smoothed_opponent_xyz_positions = opponent_xyz_positions\n",
    "\n",
    "# # visualize_two_3d_xyz(smoothed_opponent_xyz_positions, glasses_xyz_positions)\n",
    "# # visualize_two_3d_xyz(opponent_xyz_positions, glasses_xyz_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1477f570-8a4b-43a2-a55d-d42d6292a166",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "import numpy as np\n",
    "import io\n",
    "import base64\n",
    "import matplotlib.animation as animation\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from ipywidgets import interact\n",
    "\n",
    "def interactive_trajectory_view(xyz_positions1, xyz_positions2):\n",
    "    xyz_positions1 = np.array(xyz_positions1)\n",
    "    xyz_positions2 = np.array(xyz_positions2)\n",
    "\n",
    "    x1, y1 = xyz_positions1[:, 0], xyz_positions1[:, 1]\n",
    "    x2, y2 = xyz_positions2[:, 0], xyz_positions2[:, 1]\n",
    "\n",
    "    all_x = np.concatenate((x1, x2))\n",
    "    all_y = np.concatenate((y1, y2))\n",
    "\n",
    "    x_min, x_max = np.min(all_x), np.max(all_x)\n",
    "    y_min, y_max = np.min(all_y), np.max(all_y)\n",
    "\n",
    "    scale_factor = 0.5\n",
    "    max_range = max(x_max - x_min, y_max - y_min)\n",
    "    x_center = (x_max + x_min) / 2\n",
    "    y_center = (y_max + y_min) / 2\n",
    "\n",
    "    def plot_frame(frame_idx):\n",
    "        fig, ax = plt.subplots(figsize=(6, 6))\n",
    "\n",
    "        ax.set_xlim(x_center - max_range / 2 - scale_factor, x_center + max_range / 2 + scale_factor)\n",
    "        ax.set_ylim(y_center - max_range / 2 - scale_factor, y_center + max_range / 2 + scale_factor)\n",
    "        ax.set_aspect('equal')\n",
    "        ax.set_xlabel(\"X Position (m)\")\n",
    "        ax.set_ylabel(\"Y Position (m)\")\n",
    "\n",
    "        # Plot all positions up to the current frame\n",
    "        ax.plot(x1[:frame_idx+1], y1[:frame_idx+1], c='red', label='Person 1')\n",
    "        ax.plot(x2[:frame_idx+1], y2[:frame_idx+1], c='blue', label='Person 2')\n",
    "\n",
    "        # Optionally, mark the current position with a larger dot\n",
    "        ax.scatter([x1[frame_idx]], [y1[frame_idx]], c='red', s=40)\n",
    "        ax.scatter([x2[frame_idx]], [y2[frame_idx]], c='blue', s=40)\n",
    "\n",
    "        ax.legend()\n",
    "        plt.show()\n",
    "\n",
    "    interact(plot_frame, frame_idx=widgets.IntSlider(min=0, max=min(len(x1), len(x2)) - 1, step=1, value=0, description=\"Frame\"))\n",
    "\n",
    "    # Export HTML with interactive slider\n",
    "    def export_interactive_html(output_path=\"trajectory_slider.html\", frame_folder=\"frames\"):\n",
    "        os.makedirs(frame_folder, exist_ok=True)\n",
    "\n",
    "        frame_paths = []\n",
    "        for frame_idx in range(min(len(x1), len(x2))):\n",
    "            fig, ax = plt.subplots(figsize=(6, 6))\n",
    "            ax.set_xlim(x_center - max_range / 2 - scale_factor, x_center + max_range / 2 + scale_factor)\n",
    "            ax.set_ylim(y_center - max_range / 2 - scale_factor, y_center + max_range / 2 + scale_factor)\n",
    "            ax.set_aspect('equal')\n",
    "            ax.set_xlabel(\"X Position (m)\")\n",
    "            ax.set_ylabel(\"Y Position (m)\")\n",
    "            ax.plot(x1[:frame_idx+1], y1[:frame_idx+1], c='red', label='Person 1')\n",
    "            ax.plot(x2[:frame_idx+1], y2[:frame_idx+1], c='blue', label='Person 2')\n",
    "            ax.scatter([x1[frame_idx]], [y1[frame_idx]], c='red', s=40)\n",
    "            ax.scatter([x2[frame_idx]], [y2[frame_idx]], c='blue', s=40)\n",
    "            ax.legend()\n",
    "\n",
    "            frame_path = os.path.join(frame_folder, f\"frame_{frame_idx:04d}.png\")\n",
    "            fig.savefig(frame_path, dpi=100)\n",
    "            plt.close(fig)\n",
    "            frame_paths.append(frame_path)\n",
    "\n",
    "        # Write HTML with JS slider\n",
    "        with open(output_path, \"w\") as f:\n",
    "            f.write(f\"\"\"<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "    <title>Trajectory Slider</title>\n",
    "    <style>\n",
    "        body {{ font-family: sans-serif; text-align: center; }}\n",
    "        img {{ max-width: 100%; height: auto; }}\n",
    "        #slider-container {{ margin: 20px; }}\n",
    "        #frameLabel {{ margin-top: 10px; font-weight: bold; }}\n",
    "        .image-row {{ display: flex; justify-content: center; gap: 20px; flex-wrap: wrap; }}\n",
    "        .image-container {{ flex: 1 1 45%; }}\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "    <h2>Trajectory Viewer</h2>\n",
    "    <div id=\"slider-container\">\n",
    "        <input type=\"range\" min=\"0\" max=\"{len(frame_paths)-1}\" value=\"0\" id=\"frameSlider\">\n",
    "        <input type=\"number\" min=\"0\" max=\"{len(frame_paths)-1}\" value=\"0\" id=\"frameInput\">\n",
    "        <div id=\"frameLabel\">Frame: 0</div>\n",
    "    </div>\n",
    "    <div class=\"image-row\">\n",
    "        <div class=\"image-container\">\n",
    "            <h3>Trajectory Plot</h3>\n",
    "            <img id=\"trajectoryImg\" src=\"diagram_frames/frame_0000.png\" width=\"600\">\n",
    "        </div>\n",
    "        <div class=\"image-container\">\n",
    "            <h3>Video Frame</h3>\n",
    "            <img id=\"videoImg\" src=\"video_frames/frame_0000.png\" width=\"600\">\n",
    "        </div>\n",
    "    </div>\n",
    "    <script>\n",
    "        const slider = document.getElementById('frameSlider');\n",
    "        const input = document.getElementById('frameInput');\n",
    "        const trajImg = document.getElementById('trajectoryImg');\n",
    "        const videoImg = document.getElementById('videoImg');\n",
    "        const label = document.getElementById('frameLabel');\n",
    "\n",
    "        function updateFrame(val) {{\n",
    "            const frameNum = String(val).padStart(4, '0');\n",
    "            trajImg.src = 'diagram_frames/frame_' + frameNum + '.png';\n",
    "            videoImg.src = 'video_frames/frame_' + frameNum + '.png';\n",
    "            label.textContent = 'Frame: ' + val;\n",
    "            slider.value = val;\n",
    "            input.value = val;\n",
    "        }}\n",
    "\n",
    "        slider.oninput = function() {{ updateFrame(this.value); }}\n",
    "        input.onchange = function() {{ updateFrame(this.value); }}\n",
    "    </script>\n",
    "</body>\n",
    "</html>\"\"\")\n",
    "#         with open(output_path, \"w\") as f:\n",
    "#             f.write(\"\"\"<!DOCTYPE html>\n",
    "# <html>\n",
    "# <head>\n",
    "#     <title>Trajectory Slider</title>\n",
    "#     <style>\n",
    "#         body {{ font-family: sans-serif; text-align: center; }}\n",
    "#         img {{ max-width: 100%; height: auto; }}\n",
    "#         #slider-container {{ margin: 20px; }}\n",
    "#         #frameLabel {{ margin-top: 10px; font-weight: bold; }}\n",
    "#     </style>\n",
    "# </head>\n",
    "# <body>\n",
    "#     <h2>Trajectory Viewer</h2>\n",
    "#     <div id=\\\"slider-container\\\">\n",
    "#         <input type=\\\"range\\\" min=\\\"0\\\" max=\\\"{max_frame}\\\" value=\\\"0\\\" id=\\\"frameSlider\\\">\n",
    "#         <input type=\\\"number\\\" min=\\\"0\\\" max=\\\"{max_frame}\\\" value=\\\"0\\\" id=\\\"frameInput\\\">\n",
    "#         <div id=\\\"frameLabel\\\">Frame: 0</div>\n",
    "#     </div>\n",
    "#     <div>\n",
    "#         <img id=\\\"frameImg\\\" src=\\\"{folder}/frame_0000.png\\\" width=\\\"600\\\">\n",
    "#     </div>\n",
    "#     <script>\n",
    "#         const slider = document.getElementById('frameSlider');\n",
    "#         const input = document.getElementById('frameInput');\n",
    "#         const img = document.getElementById('frameImg');\n",
    "#         const label = document.getElementById('frameLabel');\n",
    "\n",
    "#         function updateFrame(val) {{\n",
    "#             const frameNum = String(val).padStart(4, '0');\n",
    "#             img.src = '{folder}/frame_' + frameNum + '.png';\n",
    "#             label.textContent = 'Frame: ' + val;\n",
    "#             slider.value = val;\n",
    "#             input.value = val;\n",
    "#         }}\n",
    "\n",
    "#         slider.oninput = function() {{ updateFrame(this.value); }}\n",
    "#         input.onchange = function() {{ updateFrame(this.value); }}\n",
    "#     </script>\n",
    "# </body>\n",
    "# </html>\"\"\".format(max_frame=len(frame_paths)-1, folder=frame_folder))\n",
    "\n",
    "        print(f\"✅ HTML + PNGs exported to: {output_path} and {frame_folder}/\")\n",
    "\n",
    "    frame_folder = os.path.join(base_dir, \"Generated_Diagrams&Frames\", video_name, \"diagram_frames\")\n",
    "    # relative_frame_folder = os.path.basename(frame_folder)\n",
    "    output_path = os.path.join(base_dir, \"Generated_Diagrams&Frames\", video_name, f\"{video_name}_trajectory_slider.html\")\n",
    "\n",
    "\n",
    "    export_interactive_html(output_path=output_path, frame_folder=frame_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7162bbf-f709-4eee-9523-cc6ad1653572",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive_trajectory_view(glasses_xyz_positions, smoothed_opponent_xyz_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa3c181-adf3-42dd-9140-9b9152b53400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def clean_xyz_sequence(xyz_seq):\n",
    "#     return [\n",
    "#         np.array(pt[\"xyz\"], dtype=np.float32) if pt is not None else np.array([0, 0, 0], dtype=np.float32)\n",
    "#         for pt in xyz_seq\n",
    "#     ]\n",
    "\n",
    "# person_id = top_ids[0]\n",
    "\n",
    "# trajectory_xyz = []\n",
    "# for frame_data in filtered_positions:\n",
    "#     trajectory_xyz.append(frame_data.get(person_id, None))\n",
    "\n",
    "# trajectory_xyz = clean_xyz_sequence(trajectory_xyz)\n",
    "\n",
    "# # Now visualize\n",
    "# interactive_trajectory_view(glasses_xyz_positions, trajectory_xyz)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "412a273b-9bbd-4d9f-bdeb-dccd64f9709a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f66ebcda941944aeb62bda083779aedc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='Frame', max=112), Output()), _dom_classes=('widget-inter…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ HTML + PNGs exported to: /Users/behnood/Downloads/S - Master Thesis - EPFL/Aria Recordings/Pierre/Generated_Diagrams&Frames/Pierre_INM_3/Pierre_INM_3_trajectory_slider.html and /Users/behnood/Downloads/S - Master Thesis - EPFL/Aria Recordings/Pierre/Generated_Diagrams&Frames/Pierre_INM_3/diagram_frames/\n"
     ]
    }
   ],
   "source": [
    "person_id = top_ids[2]\n",
    "print(person_id)\n",
    "\n",
    "# Extract their already-smoothed, fully-padded xyz trajectory\n",
    "trajectory_xyz = [frame[person_id][\"xyz\"] for frame in filtered_positions]\n",
    "\n",
    "# Visualize against glasses trajectory\n",
    "interactive_trajectory_view(glasses_xyz_positions, trajectory_xyz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "95f390d2-6870-410e-ae7a-5ec2aeec218d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'smoothed_opponent_xyz_positions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[43msmoothed_opponent_xyz_positions\u001b[49m))\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(glasses_xyz_positions))\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(opponent_xyz_positions))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'smoothed_opponent_xyz_positions' is not defined"
     ]
    }
   ],
   "source": [
    "print(len(smoothed_opponent_xyz_positions))\n",
    "print(len(glasses_xyz_positions))\n",
    "print(len(opponent_xyz_positions))\n",
    "print(len(pedestrians_xyz_positions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e0df17-21ef-4e8c-968c-38723e6ed69c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
